{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import db_connection as db_conn\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, when, isnan, count, avg, lag, unix_timestamp\n","from pyspark.sql.types import FloatType, ArrayType, IntegerType\n","from pyspark.sql.window import Window\n","from pyspark.sql import functions as F\n","from pyspark import StorageLevel\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","from datetime import timedelta, datetime\n","from functools import reduce\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/07/02 19:22:39 WARN Utils: Your hostname, NatRng-MBP.local resolves to a loopback address: 127.0.0.1; using 192.168.222.103 instead (on interface en0)\n","23/07/02 19:22:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","23/07/02 19:22:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["db_config = db_conn.config_sql\n","# Create a SparkSession\n","spark = SparkSession.builder \\\n","    .appName(\"process_tx\") \\\n","    .config(\"spark.driver.memory\", \"16g\") \\\n","    .config(\"spark.executor.memory\", \"32g\") \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["url = f\"jdbc:mariadb://{db_config['host']}:{db_config['port']}/{db_config['database']}\"\n","user = db_config['user']\n","password = db_config['password']\n","transactions_df = spark.read.format('jdbc').options(url=url, dbtable='Transactions', user=user, password=password).load()\n","block_df = spark.read.format('jdbc').options(url=url, dbtable='Blocks', user=user, password=password).load()\n","address_df = spark.read.format('jdbc').options(url=url, dbtable='Addresses', user=user, password=password).load()\n","category_df = spark.read.format('jdbc').options(url=url, dbtable='TxCategories', user=user, password=password).load()\n","contract_df = spark.read.format('jdbc').options(url=url, dbtable='Contracts', user=user, password=password).load()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Outgoing and incoming Transactions"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["outgoing_transactions = transactions_df.groupby(\"from_id\")\\\n","                             .agg(F.count(\"tx_id\").alias(\"outgoing_tx_count\"))\n","\n","incoming_transactions = transactions_df.filter(col(\"to_id\").isNotNull()).groupby(\"to_id\")\\\n","                             .agg(F.count(\"tx_id\").alias(\"incoming_tx_count\"))\n","\n","outgoing_transactions = outgoing_transactions.withColumnRenamed(\"from_id\", \"address_id\")\n","incoming_transactions = incoming_transactions.withColumnRenamed(\"to_id\", \"address_id\")\n","\n","transactions_count = outgoing_transactions.join(incoming_transactions, \"address_id\", \"outer\")\n","transactions_count = transactions_count.fillna(0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Time diff between first and last transaction"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["outgoing_timestamps = address_df.join(transactions_df, address_df.address_id == transactions_df.from_id, \"left\").select(\"address_id\", \"timestamp\")\n","outgoing_timestamps = outgoing_timestamps.na.drop(subset=[\"timestamp\"])\n","incoming_timestamps = address_df.join(transactions_df, address_df.address_id == transactions_df.to_id, \"left\").select(\"address_id\", \"timestamp\")\n","incoming_timestamps = incoming_timestamps.na.drop(subset=[\"timestamp\"])\n","\n","all_timestamps = outgoing_timestamps.union(incoming_timestamps)\n","# Group by address_id and calculate min, max timestamp\n","transactions_timestamps = all_timestamps.groupBy(\"address_id\")\\\n","                                          .agg(F.min(\"timestamp\").alias(\"first_tx_timestamp\"),\n","                                               F.max(\"timestamp\").alias(\"last_tx_timestamp\"))\n","\n","# Calculate the time difference for each address_id in minutes\n","transactions_timestamps = transactions_timestamps.withColumn(\n","    \"time_difference\",\n","    F.col(\"last_tx_timestamp\").cast(\"long\") - F.col(\"first_tx_timestamp\").cast(\"long\"))\n","\n","transactions_timestamps = transactions_timestamps.withColumn(\n","    \"time_difference_in_minutes\",\n","    (F.col(\"time_difference\") / 60))\n","\n","# Show the results\n","transactions_timestamps = transactions_timestamps.select(\"address_id\", \"time_difference_in_minutes\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["windowSpec = Window.partitionBy(\"address_id\").orderBy(\"timestamp\")\n","time_diff_secs = (unix_timestamp(col(\"timestamp\")) - lag(unix_timestamp(col(\"timestamp\"))).over(windowSpec))\n","\n","outtx_subquery = outgoing_timestamps.withColumn(\"time_diff_secs\", time_diff_secs) \\\n","    .groupBy(\"address_id\") \\\n","    .agg(avg(col(\"time_diff_secs\")).alias(\"avg_time_diff_secs\"))\n","\n","# Calculate the average time difference in minutes by dividing by 60\n","avg_outgoing_tx = outtx_subquery.withColumn(\"avg_time_diff_out_minutes\", col(\"avg_time_diff_secs\") / 60) \\\n","    .select(\"address_id\", \"avg_time_diff_out_minutes\")\n","\n","inctx_subquery = incoming_timestamps.withColumn(\"time_diff_secs\", time_diff_secs) \\\n","    .groupBy(\"address_id\") \\\n","    .agg(avg(col(\"time_diff_secs\")).alias(\"avg_time_diff_secs\"))\n","\n","# Calculate the average time difference in minutes by dividing by 60\n","avg_incoming_tx = inctx_subquery.withColumn(\"avg_time_diff_in_minutes\", col(\"avg_time_diff_secs\") / 60) \\\n","    .select(\"address_id\", \"avg_time_diff_in_minutes\")\n","\n","all_tx_subquery = all_timestamps.withColumn(\"time_diff_secs\", time_diff_secs) \\\n","    .groupBy(\"address_id\") \\\n","    .agg(avg(col(\"time_diff_secs\")).alias(\"avg_time_diff_secs\"))\n","\n","avg_total_tx = all_tx_subquery.withColumn(\"total_avg_time_diff_minutes\", col(\"avg_time_diff_secs\") / 60) \\\n","    .select(\"address_id\", \"total_avg_time_diff_minutes\")\n","\n","avg_tx = avg_outgoing_tx.join(avg_incoming_tx, \"address_id\", \"outer\")\n","avg_tx = avg_tx.join(avg_total_tx, \"address_id\", \"outer\")\n","avg_tx = avg_tx.fillna(0)\n","                                                            "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Contract Creation"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["contracts_created  = contract_df.join(transactions_df, contract_df['tx_id'] == transactions_df['tx_id'], \"left\")\\\n","                                .select(contract_df[\"contract_id\"], contract_df[\"tx_id\"], transactions_df[\"from_id\"])\n","\n","contracts_created = contracts_created.groupBy(\"from_id\").agg(F.count(\"tx_id\").alias(\"contracts_created\"))\n","contracts_created = contracts_created.withColumnRenamed(\"from_id\", \"address_id\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get Unique Received From Addresses"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["unique_received_transactions = transactions_df.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\").agg(F.countDistinct(\"from_id\").alias(\"unique_received_transactions\"))\n","unique_received_transactions = unique_received_transactions.withColumnRenamed(\"to_id\", \"address_id\")\n","unique_sent_transactions = transactions_df.groupBy(\"from_id\").agg(F.countDistinct(\"to_id\").alias(\"unique_sent_transactions\"))\n","unique_sent_transactions = unique_sent_transactions.withColumnRenamed(\"from_id\", \"address_id\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["incoming_eth = transactions_df.filter(col(\"asset\") == \"ETH\").filter(col(\"to_id\").isNotNull()) \\\n","                    .fillna({\"asset_value\": 0}) \\\n","                    .groupBy(\"to_id\").agg(F.sum(\"asset_value\").alias(\"total_incoming_eth\"))\n","incoming_eth = incoming_eth.withColumnRenamed(\"to_id\", \"address_id\")\n","\n","outgoing_eth = transactions_df.filter(col(\"asset\") == \"ETH\")\\\n","                    .fillna({\"asset_value\": 0}) \\\n","                    .groupBy(\"from_id\").agg(F.sum(\"asset_value\").alias(\"total_outgoing_eth\"))\n","outgoing_eth = outgoing_eth.withColumnRenamed(\"from_id\", \"address_id\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["erc20 transfers"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#cast erc_20_tnx asset_value to float\n","erc_20_tnx = transactions_df.filter(col(\"category_id\") == 3)\n","erc_20_tnx = erc_20_tnx.withColumn(\"asset_value\", erc_20_tnx[\"asset_value\"].cast(FloatType()))\n","outgoing_erc_20_tnx = erc_20_tnx.groupBy(\"from_id\").agg(F.count(\"tx_id\").alias(\"outgoing_erc_20_tnx\"))\n","incoming_erc_20_tnx = erc_20_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\").agg(F.count(\"tx_id\").alias(\"incoming_erc_20_tnx\"))\n","outgoing_erc_20_tnx = outgoing_erc_20_tnx.withColumnRenamed(\"from_id\", \"address_id\")\n","incoming_erc_20_tnx = incoming_erc_20_tnx.withColumnRenamed(\"to_id\", \"address_id\")\n","total_erc_20_tnx = outgoing_erc_20_tnx.join(incoming_erc_20_tnx, \"address_id\", \"outer\").fillna(0)\n","total_erc_20_tnx = total_erc_20_tnx.withColumn(\"total_erc_20_tnx\", F.col(\"outgoing_erc_20_tnx\") + F.col(\"incoming_erc_20_tnx\"))\n","total_erc_20_tnx = total_erc_20_tnx.select(\"address_id\", \"outgoing_erc_20_tnx\", \"incoming_erc_20_tnx\", \"total_erc_20_tnx\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ERC 20 ETH TX Features"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["erc20eth_out = erc_20_tnx.filter(col(\"asset\") == \"ETH\")\\\n","                .fillna({\"asset_value\": 0}) \\\n","                .groupBy(\"from_id\").agg(F.sum(\"asset_value\").alias(\"total_outgoing_erc20eth\"))\n","erc20eth_out = erc20eth_out.withColumnRenamed(\"from_id\", \"address_id\")\n","\n","erc20eth_in = erc_20_tnx.filter(col(\"asset\") == \"ETH\")\\\n","                .filter(col(\"to_id\").isNotNull()) \\\n","                .fillna({\"asset_value\": 0}) \\\n","                .groupBy(\"to_id\").agg(F.sum(\"asset_value\").alias(\"total_incoming_erc20eth\"))\n","erc20eth_in = erc20eth_in.withColumnRenamed(\"to_id\", \"address_id\")\n","\n","min_erc20token_out = erc_20_tnx.groupBy(\"from_id\") \\\n","                    .min(\"asset_value\").withColumnRenamed(\"min(asset_value)\", \"min_erc20token_out\")\n","min_erc20token_out = min_erc20token_out.withColumnRenamed(\"from_id\", \"address_id\")\n","\n","min_erc20token_in = erc_20_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\") \\\n","                    .min(\"asset_value\").withColumnRenamed(\"min(asset_value)\", \"min_erc20token_in\")\n","min_erc20token_in = min_erc20token_in.withColumnRenamed(\"to_id\", \"address_id\")\n","\n","max_erc20token_out = erc_20_tnx.groupBy(\"from_id\") \\\n","                    .max(\"asset_value\").withColumnRenamed(\"max(asset_value)\", \"max_erc20token_out\")\n","max_erc20token_out = max_erc20token_out.withColumnRenamed(\"from_id\", \"address_id\")\n","\n","max_erc20token_in = erc_20_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\") \\\n","                    .max(\"asset_value\").withColumnRenamed(\"max(asset_value)\", \"max_erc20token_in\")\n","max_erc20token_in = max_erc20token_in.withColumnRenamed(\"to_id\", \"address_id\")\n","\n","num_unique_erc20tokens_out = erc_20_tnx.groupBy(\"from_id\") \\\n","                            .agg(F.countDistinct(\"asset\").alias(\"num_unique_erc20tokens_out\"))\n","num_unique_erc20tokens_out = num_unique_erc20tokens_out.withColumnRenamed(\"from_id\", \"address_id\")\n","\n","num_unique_erc20tokens_in = erc_20_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\") \\\n","                            .agg(F.countDistinct(\"asset\").alias(\"num_unique_erc20tokens_in\"))\n","num_unique_erc20tokens_in = num_unique_erc20tokens_in.withColumnRenamed(\"to_id\", \"address_id\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ERC1155 Transactions Features"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#cast erc_20_tnx asset_value to float\n","erc_1155_tnx = transactions_df.filter(col(\"category_id\") == 1)\n","outgoing_erc_1155_tnx = erc_1155_tnx.groupBy(\"from_id\").agg(F.count(\"tx_id\").alias(\"outgoing_erc_1155_tnx\"))\n","incoming_erc_1155_tnx = erc_1155_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\").agg(F.count(\"tx_id\").alias(\"incoming_erc_1155_tnx\"))\n","outgoing_erc_1155_tnx = outgoing_erc_1155_tnx.withColumnRenamed(\"from_id\", \"address_id\")\n","incoming_erc_1155_tnx = incoming_erc_1155_tnx.withColumnRenamed(\"to_id\", \"address_id\")\n","total_erc_1155_tnx = outgoing_erc_1155_tnx.join(incoming_erc_1155_tnx, \"address_id\", \"outer\").fillna(0)\n","total_erc_1155_tnx = total_erc_1155_tnx.withColumn(\"total_erc_1155_tnx\", F.col(\"outgoing_erc_1155_tnx\") + F.col(\"incoming_erc_1155_tnx\"))\n","total_erc_1155_tnx = total_erc_1155_tnx.select(\"address_id\", \"outgoing_erc_1155_tnx\", \"incoming_erc_1155_tnx\", \"total_erc_1155_tnx\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["ERC721 TX Features"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["erc_721_tnx = transactions_df.filter(col(\"category_id\") == 5)\n","outgoing_erc_721_tnx = erc_721_tnx.groupBy(\"from_id\").agg(F.count(\"tx_id\").alias(\"outgoing_erc_721_tnx\"))\n","incoming_erc_721_tnx = erc_721_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\").agg(F.count(\"tx_id\").alias(\"incoming_erc_721_tnx\"))\n","outgoing_erc_721_tnx = outgoing_erc_721_tnx.withColumnRenamed(\"from_id\", \"address_id\")\n","incoming_erc_721_tnx = incoming_erc_721_tnx.withColumnRenamed(\"to_id\", \"address_id\")\n","total_erc_721_tnx = outgoing_erc_721_tnx.join(incoming_erc_721_tnx, \"address_id\", \"outer\").fillna(0)\n","total_erc_721_tnx = total_erc_721_tnx.withColumn(\"total_erc_721_tnx\", F.col(\"outgoing_erc_721_tnx\") + F.col(\"incoming_erc_721_tnx\"))\n","total_erc_721_tnx = total_erc_721_tnx.select(\"address_id\", \"outgoing_erc_721_tnx\", \"incoming_erc_721_tnx\", \"total_erc_721_tnx\")\n","\n","num_unique_erc721asset_out = erc_721_tnx.groupBy(\"from_id\") \\\n","                            .agg(F.countDistinct(\"asset\").alias(\"num_unique_erc721asset_out\"))\n","num_unique_erc721asset_out = num_unique_erc721asset_out.withColumnRenamed(\"from_id\", \"address_id\")\n","\n","num_unique_erc721asset_in = erc_721_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\") \\\n","                            .agg(F.countDistinct(\"asset\").alias(\"num_unique_erc721asset_in\"))\n","num_unique_erc721asset_in = num_unique_erc721asset_in.withColumnRenamed(\"to_id\", \"address_id\")\n","\n","num_unique_erc721token_out = erc_721_tnx.groupBy(\"from_id\") \\\n","                            .agg(F.countDistinct(\"erc721_token_id\").alias(\"num_unique_erc721tokens_out\"))\n","num_unique_erc721token_out = num_unique_erc721token_out.withColumnRenamed(\"from_id\", \"address_id\")\n","\n","num_unique_erc721token_in = erc_721_tnx.filter(col(\"to_id\").isNotNull()).groupBy(\"to_id\") \\\n","                            .agg(F.countDistinct(\"erc721_token_id\").alias(\"num_unique_erc721tokens_in\"))\n","num_unique_erc721tokent_in = num_unique_erc721token_in.withColumnRenamed(\"to_id\", \"address_id\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Compute Gini Coefficients of daily and monthly transactions"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["transactions_df = transactions_df.withColumn('date', F.to_date('timestamp', 'yyyy-MM-dd HH:mm:ss'))\n","transactions_df = transactions_df.withColumn('week_of_year', F.weekofyear('date'))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Aggregate tx_id counts by day for each from_id and collect as list\n","daily_from_transactions = transactions_df.groupBy('from_id', 'date').agg(F.count('tx_id').alias('daily_tx_count'))\n","daily_from_transactions = daily_from_transactions.groupBy('from_id').agg(F.collect_list('daily_tx_count').alias('daily_tx_counts'))\n","\n","# Aggregate tx_id counts by day for each to_id and collect as list\n","daily_to_transactions = transactions_df.filter(col(\"to_id\").isNotNull()).groupBy('to_id', 'date').agg(F.count('tx_id').alias('daily_tx_count'))\n","daily_to_transactions = daily_to_transactions.groupBy('to_id').agg(F.collect_list('daily_tx_count').alias('daily_tx_counts'))\n","# Aggregate tx_id counts by week for each from_id and collect as list\n","weekly_from_transactions = transactions_df.groupBy('from_id', 'week_of_year').agg(F.count('tx_id').alias('weekly_tx_count'))\n","weekly_from_transactions = weekly_from_transactions.groupBy('from_id').agg(F.collect_list('weekly_tx_count').alias('weekly_tx_counts'))\n","\n","# Aggregate tx_id counts by week for each to_id and collect as list\n","weekly_to_transactions = transactions_df.filter(col(\"to_id\").isNotNull()).groupBy('to_id', 'week_of_year').agg(F.count('tx_id').alias('weekly_tx_count'))\n","weekly_to_transactions = weekly_to_transactions.groupBy('to_id').agg(F.collect_list('weekly_tx_count').alias('weekly_tx_counts'))\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["total_transactions_out = transactions_df.select(\"from_id\", \"timestamp\", \"date\", \"week_of_year\")\n","total_transactions_in = transactions_df.filter(col(\"to_id\").isNotNull()).select(\"to_id\", \"timestamp\", \"date\", \"week_of_year\")\n","total_transactions_out = total_transactions_out.withColumnRenamed(\"from_id\", \"address_id\")\n","total_transactions_in = total_transactions_in.withColumnRenamed(\"to_id\", \"address_id\")\n","total_transactions = total_transactions_out.union(total_transactions_in)\n","\n","daily_total_transactions = total_transactions.groupBy(\"address_id\", \"date\").agg(F.count(\"timestamp\").alias(\"daily_total_tx_count\"))\n","daily_total_transactions = daily_total_transactions.groupBy(\"address_id\").agg(F.collect_list(\"daily_total_tx_count\").alias(\"daily_total_tx_counts\"))\n","\n","weekly_total_transactions = total_transactions.groupBy(\"address_id\", \"week_of_year\").agg(F.count(\"timestamp\").alias(\"weekly_total_tx_count\"))\n","weekly_total_transactions = weekly_total_transactions.groupBy(\"address_id\").agg(F.collect_list(\"weekly_total_tx_count\").alias(\"weekly_total_tx_counts\"))\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Define your UDF\n","def extend_day_list(input_list):\n","    if len(input_list) < 30:\n","        input_list += [0] * (30 - len(input_list))\n","    return input_list\n","\n","def extend_week_list(input_list):\n","    if len(input_list) < 4:\n","        input_list += [0] * (4 - len(input_list))\n","    return input_list\n","\n","# Now we need to register this function as a UDF with spark\n","udf_extend_day_list = F.udf(extend_day_list, ArrayType(IntegerType()))\n","udf_extend_week_list = F.udf(extend_week_list, ArrayType(IntegerType()))\n","\n","daily_from_transactions = daily_from_transactions.withColumn(\"daily_tx_counts\", udf_extend_day_list(daily_from_transactions['daily_tx_counts']))\n","daily_to_transactions = daily_to_transactions.withColumn(\"daily_tx_counts\", udf_extend_day_list(daily_to_transactions['daily_tx_counts']))\n","\n","weekly_from_transactions = weekly_from_transactions.withColumn(\"weekly_tx_counts\", udf_extend_week_list(weekly_from_transactions['weekly_tx_counts']))\n","weekly_to_transactions = weekly_to_transactions.withColumn(\"weekly_tx_counts\", udf_extend_week_list(weekly_to_transactions['weekly_tx_counts']))\n","\n","daily_total_transactions = daily_total_transactions.withColumn(\"daily_total_tx_counts\", udf_extend_day_list(daily_total_transactions['daily_total_tx_counts']))\n","weekly_total_transactions = weekly_total_transactions.withColumn(\"weekly_total_tx_counts\", udf_extend_week_list(weekly_total_transactions['weekly_total_tx_counts']))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def calculate_gini_idx(x):\n","    x = sorted(x)  # sort the list\n","    n = len(x)\n","    total = sum((i+1) * xi for i, xi in enumerate(x))\n","    gini_index = (2 * total) / (n * sum(x)) - (n + 1) / n\n","    return gini_index\n","\n","udf_calculate_gini_idx = F.udf(calculate_gini_idx, FloatType())\n","\n","daily_from_transactions = daily_from_transactions.withColumn('daily_from_gini_index', udf_calculate_gini_idx('daily_tx_counts'))\n","daily_to_transactions = daily_to_transactions.withColumn('daily_to_gini_index', udf_calculate_gini_idx('daily_tx_counts'))\n","\n","weekly_from_transactions = weekly_from_transactions.withColumn('weekly_from_gini_index', udf_calculate_gini_idx('weekly_tx_counts'))\n","weekly_to_transactions = weekly_to_transactions.withColumn('weekly_to_gini_index', udf_calculate_gini_idx('weekly_tx_counts'))\n","\n","daily_total_transactions = daily_total_transactions.withColumn('daily_total_gini_index', udf_calculate_gini_idx('daily_total_tx_counts'))\n","weekly_total_transactions = weekly_total_transactions.withColumn('weekly_total_gini_index', udf_calculate_gini_idx('weekly_total_tx_counts'))\n","\n","# Rename the id columns before joining\n","daily_from_transactions = daily_from_transactions.withColumnRenamed(\"from_id\", \"address_id\")\n","daily_to_transactions = daily_to_transactions.withColumnRenamed(\"to_id\", \"address_id\")\n","weekly_from_transactions = weekly_from_transactions.withColumnRenamed(\"from_id\", \"address_id\")\n","weekly_to_transactions = weekly_to_transactions.withColumnRenamed(\"to_id\", \"address_id\")\n","\n","# Prepare the list of all dataframes to join\n","gini_dfs = [daily_from_transactions, daily_to_transactions, weekly_from_transactions, \n","       weekly_to_transactions, daily_total_transactions, weekly_total_transactions]\n","\n","daily_gini_index = reduce(lambda a, b: a.join(b, \"address_id\", \"outer\"), gini_dfs[0:2])\n","daily_gini_index = daily_gini_index.select(\"address_id\", \"daily_from_gini_index\", \"daily_to_gini_index\")\n"," \n","weekly_gini_index = reduce(lambda a, b: a.join(b, \"address_id\", \"outer\"), gini_dfs[2:4])\n","weekly_gini_index = weekly_gini_index.select(\"address_id\", \"weekly_from_gini_index\", \"weekly_to_gini_index\")\n","\n","total_gini_index = reduce(lambda a, b: a.join(b, \"address_id\", \"outer\"), gini_dfs[4:6])\n","total_gini_index = total_gini_index.select(\"address_id\", \"daily_total_gini_index\", \"weekly_total_gini_index\")\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["daily_gini_index.write.mode('overwrite').parquet(\"data/parquet_files/daily_gini_idx.parquet\")\n","weekly_gini_index.write.mode('overwrite').parquet(\"data/parquet_files/weekly_gini_idx.parquet\")\n","total_gini_index.write.mode('overwrite').parquet(\"data/parquet_files/total_gini_idx.parquet\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Recency Transactions"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["gamma = 0.3\n","window_period = Window.partitionBy(\"address_id\").orderBy(\"timestamp\")\n","\n","def compute_recency(time_delta):\n","    if time_delta is None:\n","        tx_recency = 0\n","    else:\n","        tx_recency = math.exp(-gamma * time_delta)\n","    return tx_recency\n","\n","udf_tx_recency = F.udf(compute_recency, FloatType())\n","\n","outgoing_tx_times = address_df.join(transactions_df, address_df.address_id == transactions_df.from_id, \"left\").select(\"tx_id\", \"address_id\", \"timestamp\")\n","incoming_tx_times = address_df.join(transactions_df, address_df.address_id == transactions_df.to_id, \"left\").select(\"tx_id\", \"address_id\", \"timestamp\")\n","\n","# Calculate the time difference in days\n","time_diff_days = (unix_timestamp(col(\"timestamp\")) - lag(unix_timestamp(col(\"timestamp\"))).over(window_period)) / 86400\n","\n","# Apply the time difference and compute recency function to the outgoing transactions\n","outgoing_tx_times = outgoing_tx_times.withColumn(\"time_diff_days\", time_diff_days)\n","outgoing_tx_times = outgoing_tx_times.withColumn(\"recency\", udf_tx_recency(col(\"time_diff_days\")))\n","outgoing_tx_times = outgoing_tx_times.fillna({\"recency\": 0})\n","outgoing_tx_times = outgoing_tx_times.select(\"tx_id\", \"address_id\", \"timestamp\", \"time_diff_days\", \"recency\")\n","outgoing_recency_avg = outgoing_tx_times.groupBy(\"address_id\").agg(F.median('recency').alias(\"median_recency_out\"))\n","\n","# Apply the time difference and compute recency function to the incoming transactions\n","incoming_tx_times = incoming_tx_times.withColumn(\"time_diff_days\", time_diff_days)\n","incoming_tx_times = incoming_tx_times.withColumn(\"recency\", udf_tx_recency(col(\"time_diff_days\")))\n","incoming_tx_times = incoming_tx_times.fillna({\"recency\": 0})\n","incoming_tx_times = incoming_tx_times.select(\"tx_id\", \"address_id\", \"timestamp\",\"time_diff_days\", \"recency\")\n","incoming_recency_avg = incoming_tx_times.groupBy(\"address_id\").agg(F.median('recency').alias(\"median_recency_in\"))\n","\n","\n","# Join the two dataframes\n","recency_avg = outgoing_recency_avg.join(incoming_recency_avg, \"address_id\", \"outer\")\n","recency_avg = recency_avg.fillna(0)\n","recency_avg = recency_avg.select(\"address_id\", \"median_recency_out\", \"median_recency_in\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["outgoing_tx_times.write.mode('overwrite').parquet(\"data/parquet_files/outgoing_tx_times_train.parquet\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["EDA for recency metric"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out_tx_df = pd.read_parquet(\"data/parquet_files/outgoing_tx_times_train.parquet\")\n","# Drop rows with null values in \"time_diff_days\" column\n","out_tx_df = out_tx_df.dropna(subset=['time_diff_days'])\n","grouped_out_tx_df = out_tx_df.groupby('address_id')['time_diff_days'].agg(list).reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tx_id</th>\n","      <th>address_id</th>\n","      <th>timestamp</th>\n","      <th>time_diff_days</th>\n","      <th>recency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>30398382.0</td>\n","      <td>28</td>\n","      <td>2022-05-04 04:10:03</td>\n","      <td>2.043507</td>\n","      <td>0.541695</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>62416924.0</td>\n","      <td>28</td>\n","      <td>2022-05-04 20:16:11</td>\n","      <td>0.670926</td>\n","      <td>0.817685</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>28981524.0</td>\n","      <td>28</td>\n","      <td>2022-05-06 09:41:35</td>\n","      <td>1.435417</td>\n","      <td>0.650103</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>16297456.0</td>\n","      <td>28</td>\n","      <td>2022-05-08 11:15:53</td>\n","      <td>2.065486</td>\n","      <td>0.538135</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>30769846.0</td>\n","      <td>28</td>\n","      <td>2022-05-09 10:54:33</td>\n","      <td>0.582940</td>\n","      <td>0.839556</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>58034960</th>\n","      <td>45524364.0</td>\n","      <td>7201918</td>\n","      <td>2022-05-26 22:03:30</td>\n","      <td>6.919016</td>\n","      <td>0.125468</td>\n","    </tr>\n","    <tr>\n","      <th>58034988</th>\n","      <td>42097284.0</td>\n","      <td>7203021</td>\n","      <td>2022-05-14 12:45:00</td>\n","      <td>5.129167</td>\n","      <td>0.214649</td>\n","    </tr>\n","    <tr>\n","      <th>58035304</th>\n","      <td>10708884.0</td>\n","      <td>7213363</td>\n","      <td>2022-05-22 03:34:52</td>\n","      <td>2.464213</td>\n","      <td>0.477465</td>\n","    </tr>\n","    <tr>\n","      <th>58035424</th>\n","      <td>33834711.0</td>\n","      <td>7217031</td>\n","      <td>2022-05-07 16:53:28</td>\n","      <td>2.391377</td>\n","      <td>0.488013</td>\n","    </tr>\n","    <tr>\n","      <th>58035488</th>\n","      <td>16298940.0</td>\n","      <td>7219271</td>\n","      <td>2022-05-09 17:32:32</td>\n","      <td>0.797431</td>\n","      <td>0.787234</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4338419 rows Ã— 5 columns</p>\n","</div>"],"text/plain":["               tx_id  address_id           timestamp  time_diff_days   recency\n","4         30398382.0          28 2022-05-04 04:10:03        2.043507  0.541695\n","6         62416924.0          28 2022-05-04 20:16:11        0.670926  0.817685\n","20        28981524.0          28 2022-05-06 09:41:35        1.435417  0.650103\n","48        16297456.0          28 2022-05-08 11:15:53        2.065486  0.538135\n","84        30769846.0          28 2022-05-09 10:54:33        0.582940  0.839556\n","...              ...         ...                 ...             ...       ...\n","58034960  45524364.0     7201918 2022-05-26 22:03:30        6.919016  0.125468\n","58034988  42097284.0     7203021 2022-05-14 12:45:00        5.129167  0.214649\n","58035304  10708884.0     7213363 2022-05-22 03:34:52        2.464213  0.477465\n","58035424  33834711.0     7217031 2022-05-07 16:53:28        2.391377  0.488013\n","58035488  16298940.0     7219271 2022-05-09 17:32:32        0.797431  0.787234\n","\n","[4338419 rows x 5 columns]"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["#select rows with recency above 0.1 and less than 0.9\n","recency_df = out_tx_df[(out_tx_df['recency'] > 0.1) & (out_tx_df['recency'] < 0.9)] \n","recency_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grouped_out_tx_df['skewness'] = grouped_out_tx_df['time_diff_days'].apply(lambda x: pd.Series(x).skew())\n","skewness_symmetrical = grouped_out_tx_df[(grouped_out_tx_df['skewness'] < 0.5) & (grouped_out_tx_df['skewness'] > -0.5)]\n","skewness_asymmetrical = grouped_out_tx_df[(grouped_out_tx_df['skewness'] >= 0.5) | (grouped_out_tx_df['skewness'] <= -0.5)]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Check For Skewness"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of addresses with symmetrical skewness:  70151\n","Number of addresses with asymmetrical skewness:  1116531\n"]}],"source":["print(\"Number of addresses with symmetrical skewness: \", len(skewness_symmetrical))\n","print(\"Number of addresses with asymmetrical skewness: \", len(skewness_asymmetrical))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Gamma decay value selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/xs/x2x4yg29089c8t_v4z9nymz40000gn/T/ipykernel_15452/2256060580.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  grouped_out_tx_df['median'] = grouped_out_tx_df['time_diff_days'].apply(lambda x: pd.Series(x).median())\n"]}],"source":["grouped_out_tx_df['median'] = grouped_out_tx_df['time_diff_days'].apply(lambda x: pd.Series(x).median())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA61UlEQVR4nO3df1RU94H//xcI3Iws3mJYmIwx0ezmGA0mTbHrryR4GkFT0O1222yCTuNJlm3WX6FgEm26G+s5AWssaStrrN09SXuSSM7nGLJptRRis1iOoBSlAa1N9lRFEcSmw4xa+RF4f/9Ivd+9YogYDJX7fJxz/7j3vpj7vmM788p77p2JMsYYAQAAeFD0cA8AAABguFCEAACAZ1GEAACAZ1GEAACAZ1GEAACAZ1GEAACAZ1GEAACAZ1GEAACAZ8UM9wD+0vX19enkyZNKSEhQVFTUcA8HAABcBmOMzpw5o0AgoOjoj573oQh9jJMnT2r8+PHDPQwAAHAFjh8/rhtvvPEj91OEPkZCQoKkD5/IMWPGDPNoAADA5YhEIho/frzzPv5RKEIf48LHYWPGjKEIAQBwjfm4y1q4WBoAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHhWzHAPwOsmrN7hWj+6PmuYRgIAgPcwIwQAADyLIgQAADyLIgQAADyLIgQAADyLIgQAADyLIgQAADyLIgQAADyLIgQAADyLIgQAADyLIgQAADyLIgQAADxrUEXogw8+0Le+9S1NnDhRPp9Pt9xyi9atW6e+vj4nY4zR2rVrFQgE5PP5NGfOHB08eND1OF1dXVqxYoWSkpIUHx+vhQsX6sSJE65MKBRSMBiUbduybVvBYFAdHR2uTHNzsxYsWKD4+HglJSVp5cqV6u7udmUaGxuVnp4un8+ncePGad26dTLGDOa0AQDACDWoIvSd73xHW7ZsUUlJiX77299qw4YNeu6557Rp0yYns2HDBhUXF6ukpER1dXXy+/3KyMjQmTNnnExeXp7KyspUWlqq6upqnT17VtnZ2ert7XUyOTk5amhoUHl5ucrLy9XQ0KBgMOjs7+3tVVZWls6dO6fq6mqVlpZq+/btKigocDKRSEQZGRkKBAKqq6vTpk2btHHjRhUXF1/RkwUAAEYYMwhZWVnmkUcecW378pe/bBYvXmyMMaavr8/4/X6zfv16Z39nZ6exbdts2bLFGGNMR0eHiY2NNaWlpU6mpaXFREdHm/LycmOMMYcOHTKSTG1trZOpqakxkszhw4eNMcbs3LnTREdHm5aWFiezbds2Y1mWCYfDxhhjNm/ebGzbNp2dnU6mqKjIBAIB09fXd1nnHA6HjSTnMYfazU/9zLUAAIBP7nLfvwc1I3T33Xdr165devfddyVJv/nNb1RdXa0vfvGLkqQjR46ora1NmZmZzt9YlqX09HTt2bNHklRfX6+enh5XJhAIKDU11cnU1NTItm1Nnz7dycyYMUO2bbsyqampCgQCTmbevHnq6upSfX29k0lPT5dlWa7MyZMndfTo0UueY1dXlyKRiGsBAAAjU8xgwk899ZTC4bBuu+02jRo1Sr29vXr22Wf10EMPSZLa2tokSSkpKa6/S0lJ0bFjx5xMXFycEhMT+2Uu/H1bW5uSk5P7HT85OdmVufg4iYmJiouLc2UmTJjQ7zgX9k2cOLHfMYqKivTtb3/7458MAABwzRvUjNBrr72ml19+Wa+++qr279+vH//4x9q4caN+/OMfu3JRUVGudWNMv20XuzhzqfxQZMyfL5T+qPGsWbNG4XDYWY4fPz7guAEAwLVrUDNCTzzxhFavXq0HH3xQkjR16lQdO3ZMRUVFevjhh+X3+yV9ONtyww03OH/X3t7uzMT4/X51d3crFAq5ZoXa29s1a9YsJ3Pq1Kl+xz99+rTrcfbu3evaHwqF1NPT48pcmB36v8eR+s9aXWBZluujNAAAMHINakboT3/6k6Kj3X8yatQo5/b5iRMnyu/3q7Ky0tnf3d2tqqoqp+SkpaUpNjbWlWltbVVTU5OTmTlzpsLhsPbt2+dk9u7dq3A47Mo0NTWptbXVyVRUVMiyLKWlpTmZ3bt3u26pr6ioUCAQ6PeRGQAA8J5BFaEFCxbo2Wef1Y4dO3T06FGVlZWpuLhY//AP/yDpw4+b8vLyVFhYqLKyMjU1NWnJkiUaPXq0cnJyJEm2bevRRx9VQUGBdu3apQMHDmjx4sWaOnWq5s6dK0maPHmy5s+fr9zcXNXW1qq2tla5ubnKzs7WpEmTJEmZmZmaMmWKgsGgDhw4oF27dmnVqlXKzc3VmDFjJH14C75lWVqyZImamppUVlamwsJC5efnf+xHdQAAwAMGcytaJBIxjz/+uLnpppvMddddZ2655Rbz9NNPm66uLifT19dnnnnmGeP3+41lWebee+81jY2Nrsc5f/68Wb58uRk7dqzx+XwmOzvbNDc3uzLvv/++WbRokUlISDAJCQlm0aJFJhQKuTLHjh0zWVlZxufzmbFjx5rly5e7bpU3xph33nnH3HPPPcayLOP3+83atWsv+9Z5Y7h9HgCAa9Hlvn9HGcPXLA8kEonItm2Fw2FnpmkoTVi9w7V+dH3WkB8DAACvudz3b35rDAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeBZFCAAAeNagitCECRMUFRXVb1m2bJkkyRijtWvXKhAIyOfzac6cOTp48KDrMbq6urRixQolJSUpPj5eCxcu1IkTJ1yZUCikYDAo27Zl27aCwaA6OjpcmebmZi1YsEDx8fFKSkrSypUr1d3d7co0NjYqPT1dPp9P48aN07p162SMGcwpAwCAEWxQRaiurk6tra3OUllZKUn66le/KknasGGDiouLVVJSorq6Ovn9fmVkZOjMmTPOY+Tl5amsrEylpaWqrq7W2bNnlZ2drd7eXieTk5OjhoYGlZeXq7y8XA0NDQoGg87+3t5eZWVl6dy5c6qurlZpaam2b9+ugoICJxOJRJSRkaFAIKC6ujpt2rRJGzduVHFx8ZU9UwAAYOQxn8Djjz9u/uZv/sb09fWZvr4+4/f7zfr16539nZ2dxrZts2XLFmOMMR0dHSY2NtaUlpY6mZaWFhMdHW3Ky8uNMcYcOnTISDK1tbVOpqamxkgyhw8fNsYYs3PnThMdHW1aWlqczLZt24xlWSYcDhtjjNm8ebOxbdt0dnY6maKiIhMIBExfX99ln2M4HDaSnMcdajc/9TPXAgAAPrnLff++4muEuru79fLLL+uRRx5RVFSUjhw5ora2NmVmZjoZy7KUnp6uPXv2SJLq6+vV09PjygQCAaWmpjqZmpoa2bat6dOnO5kZM2bItm1XJjU1VYFAwMnMmzdPXV1dqq+vdzLp6emyLMuVOXnypI4ePfqR59XV1aVIJOJaAADAyHTFReiNN95QR0eHlixZIklqa2uTJKWkpLhyKSkpzr62tjbFxcUpMTFxwExycnK/4yUnJ7syFx8nMTFRcXFxA2YurF/IXEpRUZFzbZJt2xo/fvxHPwkAAOCadsVF6L/+6790//33u2ZlJCkqKsq1bozpt+1iF2culR+KjPnzhdIDjWfNmjUKh8POcvz48QHHDgAArl1XVISOHTumt956S//8z//sbPP7/ZL6z7a0t7c7MzF+v1/d3d0KhUIDZk6dOtXvmKdPn3ZlLj5OKBRST0/PgJn29nZJ/Wet/i/LsjRmzBjXAgAARqYrKkIvvviikpOTlZWV5WybOHGi/H6/cyeZ9OF1RFVVVZo1a5YkKS0tTbGxsa5Ma2urmpqanMzMmTMVDoe1b98+J7N3716Fw2FXpqmpSa2trU6moqJClmUpLS3Nyezevdt1S31FRYUCgYAmTJhwJacNAABGmEEXob6+Pr344ot6+OGHFRMT42yPiopSXl6eCgsLVVZWpqamJi1ZskSjR49WTk6OJMm2bT366KMqKCjQrl27dODAAS1evFhTp07V3LlzJUmTJ0/W/PnzlZubq9raWtXW1io3N1fZ2dmaNGmSJCkzM1NTpkxRMBjUgQMHtGvXLq1atUq5ubnODE5OTo4sy9KSJUvU1NSksrIyFRYWKj8//2M/qgMAAN4Q8/ERt7feekvNzc165JFH+u178skndf78eS1dulShUEjTp09XRUWFEhISnMzzzz+vmJgYPfDAAzp//rzuu+8+vfTSSxo1apSTeeWVV7Ry5Urn7rKFCxeqpKTE2T9q1Cjt2LFDS5cu1ezZs+Xz+ZSTk6ONGzc6Gdu2VVlZqWXLlmnatGlKTExUfn6+8vPzB3vKAABghIoyhq9aHkgkEpFt2wqHw1fleqEJq3e41o+uz/qIJAAAuFyX+/7Nb40BAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPGnQRamlp0eLFi3X99ddr9OjR+uxnP6v6+npnvzFGa9euVSAQkM/n05w5c3Tw4EHXY3R1dWnFihVKSkpSfHy8Fi5cqBMnTrgyoVBIwWBQtm3Ltm0Fg0F1dHS4Ms3NzVqwYIHi4+OVlJSklStXqru725VpbGxUenq6fD6fxo0bp3Xr1skYM9jTBgAAI9CgilAoFNLs2bMVGxurn//85zp06JC++93v6jOf+YyT2bBhg4qLi1VSUqK6ujr5/X5lZGTozJkzTiYvL09lZWUqLS1VdXW1zp49q+zsbPX29jqZnJwcNTQ0qLy8XOXl5WpoaFAwGHT29/b2KisrS+fOnVN1dbVKS0u1fft2FRQUOJlIJKKMjAwFAgHV1dVp06ZN2rhxo4qLi6/kuQIAACONGYSnnnrK3H333R+5v6+vz/j9frN+/XpnW2dnp7Ft22zZssUYY0xHR4eJjY01paWlTqalpcVER0eb8vJyY4wxhw4dMpJMbW2tk6mpqTGSzOHDh40xxuzcudNER0eblpYWJ7Nt2zZjWZYJh8PGGGM2b95sbNs2nZ2dTqaoqMgEAgHT19d3WeccDoeNJOcxh9rNT/3MtQAAgE/uct+/BzUj9Oabb2ratGn66le/quTkZN1111360Y9+5Ow/cuSI2tralJmZ6WyzLEvp6enas2ePJKm+vl49PT2uTCAQUGpqqpOpqamRbduaPn26k5kxY4Zs23ZlUlNTFQgEnMy8efPU1dXlfFRXU1Oj9PR0WZblypw8eVJHjx695Dl2dXUpEom4FgAAMDINqgj9/ve/1wsvvKBbb71Vv/jFL/TYY49p5cqV+slPfiJJamtrkySlpKS4/i4lJcXZ19bWpri4OCUmJg6YSU5O7nf85ORkV+bi4yQmJiouLm7AzIX1C5mLFRUVOdcl2bat8ePHf8yzAgAArlWDKkJ9fX363Oc+p8LCQt111136+te/rtzcXL3wwguuXFRUlGvdGNNv28UuzlwqPxQZ8+cLpT9qPGvWrFE4HHaW48ePDzhuAABw7RpUEbrhhhs0ZcoU17bJkyerublZkuT3+yX1n21pb293ZmL8fr+6u7sVCoUGzJw6darf8U+fPu3KXHycUCiknp6eATPt7e2S+s9aXWBZlsaMGeNaAADAyDSoIjR79mz97ne/c2179913dfPNN0uSJk6cKL/fr8rKSmd/d3e3qqqqNGvWLElSWlqaYmNjXZnW1lY1NTU5mZkzZyocDmvfvn1OZu/evQqHw65MU1OTWltbnUxFRYUsy1JaWpqT2b17t+uW+oqKCgUCAU2YMGEwpw4AAEaiwVyBvW/fPhMTE2OeffZZ895775lXXnnFjB492rz88stOZv369ca2bfP666+bxsZG89BDD5kbbrjBRCIRJ/PYY4+ZG2+80bz11ltm//795gtf+IK58847zQcffOBk5s+fb+644w5TU1NjampqzNSpU012draz/4MPPjCpqanmvvvuM/v37zdvvfWWufHGG83y5cudTEdHh0lJSTEPPfSQaWxsNK+//roZM2aM2bhx42WfM3eNAQBw7bnc9+9BFSFjjPnpT39qUlNTjWVZ5rbbbjNbt2517e/r6zPPPPOM8fv9xrIsc++995rGxkZX5vz582b58uVm7NixxufzmezsbNPc3OzKvP/++2bRokUmISHBJCQkmEWLFplQKOTKHDt2zGRlZRmfz2fGjh1rli9f7rpV3hhj3nnnHXPPPfcYy7KM3+83a9euvexb542hCAEAcC263PfvKGP4muWBRCIR2batcDh8Va4XmrB6h2v96PqsIT8GAABec7nv3/zWGAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8KxBFaG1a9cqKirKtfj9fme/MUZr165VIBCQz+fTnDlzdPDgQddjdHV1acWKFUpKSlJ8fLwWLlyoEydOuDKhUEjBYFC2bcu2bQWDQXV0dLgyzc3NWrBggeLj45WUlKSVK1equ7vblWlsbFR6erp8Pp/GjRundevWyRgzmFMGAAAj2KBnhG6//Xa1trY6S2Njo7Nvw4YNKi4uVklJierq6uT3+5WRkaEzZ844mby8PJWVlam0tFTV1dU6e/assrOz1dvb62RycnLU0NCg8vJylZeXq6GhQcFg0Nnf29urrKwsnTt3TtXV1SotLdX27dtVUFDgZCKRiDIyMhQIBFRXV6dNmzZp48aNKi4uHvSTBAAARigzCM8884y58847L7mvr6/P+P1+s379emdbZ2ensW3bbNmyxRhjTEdHh4mNjTWlpaVOpqWlxURHR5vy8nJjjDGHDh0ykkxtba2TqampMZLM4cOHjTHG7Ny500RHR5uWlhYns23bNmNZlgmHw8YYYzZv3mxs2zadnZ1OpqioyAQCAdPX13fZ5xwOh40k53GH2s1P/cy1AACAT+5y378HPSP03nvvKRAIaOLEiXrwwQf1+9//XpJ05MgRtbW1KTMz08lalqX09HTt2bNHklRfX6+enh5XJhAIKDU11cnU1NTItm1Nnz7dycyYMUO2bbsyqampCgQCTmbevHnq6upSfX29k0lPT5dlWa7MyZMndfTo0Y88v66uLkUiEdcCAABGpkEVoenTp+snP/mJfvGLX+hHP/qR2traNGvWLL3//vtqa2uTJKWkpLj+JiUlxdnX1tamuLg4JSYmDphJTk7ud+zk5GRX5uLjJCYmKi4ubsDMhfULmUspKipyrk2ybVvjx48f+EkBAADXrEEVofvvv1//+I//qKlTp2ru3LnasWOHJOnHP/6xk4mKinL9jTGm37aLXZy5VH4oMubPF0oPNJ41a9YoHA47y/HjxwccOwAAuHZ9otvn4+PjNXXqVL333nvO3WMXz7a0t7c7MzF+v1/d3d0KhUIDZk6dOtXvWKdPn3ZlLj5OKBRST0/PgJn29nZJ/Wet/i/LsjRmzBjXAgAARqZPVIS6urr029/+VjfccIMmTpwov9+vyspKZ393d7eqqqo0a9YsSVJaWppiY2NdmdbWVjU1NTmZmTNnKhwOa9++fU5m7969CofDrkxTU5NaW1udTEVFhSzLUlpampPZvXu365b6iooKBQIBTZgw4ZOcNgAAGCEGVYRWrVqlqqoqHTlyRHv37tVXvvIVRSIRPfzww4qKilJeXp4KCwtVVlampqYmLVmyRKNHj1ZOTo4kybZtPfrooyooKNCuXbt04MABLV682PmoTZImT56s+fPnKzc3V7W1taqtrVVubq6ys7M1adIkSVJmZqamTJmiYDCoAwcOaNeuXVq1apVyc3OdGZycnBxZlqUlS5aoqalJZWVlKiwsVH5+/sd+VAcAALwhZjDhEydO6KGHHtIf/vAH/fVf/7VmzJih2tpa3XzzzZKkJ598UufPn9fSpUsVCoU0ffp0VVRUKCEhwXmM559/XjExMXrggQd0/vx53XfffXrppZc0atQoJ/PKK69o5cqVzt1lCxcuVElJibN/1KhR2rFjh5YuXarZs2fL5/MpJydHGzdudDK2bauyslLLli3TtGnTlJiYqPz8fOXn51/ZMwUAAEacKGP4quWBRCIR2batcDh8Va4XmrB6h2v96PqsIT8GAABec7nv3/zWGAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8KxPVISKiooUFRWlvLw8Z5sxRmvXrlUgEJDP59OcOXN08OBB1991dXVpxYoVSkpKUnx8vBYuXKgTJ064MqFQSMFgULZty7ZtBYNBdXR0uDLNzc1asGCB4uPjlZSUpJUrV6q7u9uVaWxsVHp6unw+n8aNG6d169bJGPNJThsAAIwQV1yE6urqtHXrVt1xxx2u7Rs2bFBxcbFKSkpUV1cnv9+vjIwMnTlzxsnk5eWprKxMpaWlqq6u1tmzZ5Wdna3e3l4nk5OTo4aGBpWXl6u8vFwNDQ0KBoPO/t7eXmVlZencuXOqrq5WaWmptm/froKCAicTiUSUkZGhQCCguro6bdq0SRs3blRxcfGVnjYAABhJzBU4c+aMufXWW01lZaVJT083jz/+uDHGmL6+PuP3+8369eudbGdnp7Ft22zZssUYY0xHR4eJjY01paWlTqalpcVER0eb8vJyY4wxhw4dMpJMbW2tk6mpqTGSzOHDh40xxuzcudNER0eblpYWJ7Nt2zZjWZYJh8PGGGM2b95sbNs2nZ2dTqaoqMgEAgHT19d3WecaDoeNJOcxh9rNT/3MtQAAgE/uct+/r2hGaNmyZcrKytLcuXNd248cOaK2tjZlZmY62yzLUnp6uvbs2SNJqq+vV09PjysTCASUmprqZGpqamTbtqZPn+5kZsyYIdu2XZnU1FQFAgEnM2/ePHV1dam+vt7JpKeny7IsV+bkyZM6evToJc+tq6tLkUjEtQAAgJFp0EWotLRU+/fvV1FRUb99bW1tkqSUlBTX9pSUFGdfW1ub4uLilJiYOGAmOTm53+MnJye7MhcfJzExUXFxcQNmLqxfyFysqKjIuS7Jtm2NHz/+kjkAAHDtG1QROn78uB5//HG9/PLLuu666z4yFxUV5Vo3xvTbdrGLM5fKD0XG/PlC6Y8az5o1axQOh53l+PHjA44bAABcuwZVhOrr69Xe3q60tDTFxMQoJiZGVVVV+sEPfqCYmJiPnG1pb2939vn9fnV3dysUCg2YOXXqVL/jnz592pW5+DihUEg9PT0DZtrb2yX1n7W6wLIsjRkzxrUAAICRaVBF6L777lNjY6MaGhqcZdq0aVq0aJEaGhp0yy23yO/3q7Ky0vmb7u5uVVVVadasWZKktLQ0xcbGujKtra1qampyMjNnzlQ4HNa+ffuczN69exUOh12ZpqYmtba2OpmKigpZlqW0tDQns3v3btct9RUVFQoEApowYcJgTh0AAIxAMYMJJyQkKDU11bUtPj5e119/vbM9Ly9PhYWFuvXWW3XrrbeqsLBQo0ePVk5OjiTJtm09+uijKigo0PXXX6+xY8dq1apVmjp1qnPx9eTJkzV//nzl5ubqhz/8oSTpX/7lX5Sdna1JkyZJkjIzMzVlyhQFg0E999xz+uMf/6hVq1YpNzfXmcXJycnRt7/9bS1ZskTf/OY39d5776mwsFD//u///rEf1QEAgJFvUEXocjz55JM6f/68li5dqlAopOnTp6uiokIJCQlO5vnnn1dMTIweeOABnT9/Xvfdd59eeukljRo1ysm88sorWrlypXN32cKFC1VSUuLsHzVqlHbs2KGlS5dq9uzZ8vl8ysnJ0caNG52MbduqrKzUsmXLNG3aNCUmJio/P1/5+flDfdoAAOAaFGUMX7M8kEgkItu2FQ6Hr8r1QhNW73CtH12fNeTHAADAay73/ZvfGgMAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ5FEQIAAJ41qCL0wgsv6I477tCYMWM0ZswYzZw5Uz//+c+d/cYYrV27VoFAQD6fT3PmzNHBgwddj9HV1aUVK1YoKSlJ8fHxWrhwoU6cOOHKhEIhBYNB2bYt27YVDAbV0dHhyjQ3N2vBggWKj49XUlKSVq5cqe7ublemsbFR6enp8vl8GjdunNatWydjzGBOGQAAjGCDKkI33nij1q9fr1//+tf69a9/rS984Qv6+7//e6fsbNiwQcXFxSopKVFdXZ38fr8yMjJ05swZ5zHy8vJUVlam0tJSVVdX6+zZs8rOzlZvb6+TycnJUUNDg8rLy1VeXq6GhgYFg0Fnf29vr7KysnTu3DlVV1ertLRU27dvV0FBgZOJRCLKyMhQIBBQXV2dNm3apI0bN6q4uPiKnywAADDCmE8oMTHR/Od//qfp6+szfr/frF+/3tnX2dlpbNs2W7ZsMcYY09HRYWJjY01paamTaWlpMdHR0aa8vNwYY8yhQ4eMJFNbW+tkampqjCRz+PBhY4wxO3fuNNHR0aalpcXJbNu2zViWZcLhsDHGmM2bNxvbtk1nZ6eTKSoqMoFAwPT19V32+YXDYSPJedyhdvNTP3MtAADgk7vc9+8rvkaot7dXpaWlOnfunGbOnKkjR46ora1NmZmZTsayLKWnp2vPnj2SpPr6evX09LgygUBAqampTqampka2bWv69OlOZsaMGbJt25VJTU1VIBBwMvPmzVNXV5fq6+udTHp6uizLcmVOnjypo0ePfuR5dXV1KRKJuBYAADAyDboINTY26q/+6q9kWZYee+wxlZWVacqUKWpra5MkpaSkuPIpKSnOvra2NsXFxSkxMXHATHJycr/jJicnuzIXHycxMVFxcXEDZi6sX8hcSlFRkXNtkm3bGj9+/MBPCAAAuGYNughNmjRJDQ0Nqq2t1b/+67/q4Ycf1qFDh5z9UVFRrrwxpt+2i12cuVR+KDLmzxdKDzSeNWvWKBwOO8vx48cHHDsAALh2DboIxcXF6W//9m81bdo0FRUV6c4779T3v/99+f1+Sf1nW9rb252ZGL/fr+7uboVCoQEzp06d6nfc06dPuzIXHycUCqmnp2fATHt7u6T+s1b/l2VZzl1xFxYAADAyfeLvETLGqKurSxMnTpTf71dlZaWzr7u7W1VVVZo1a5YkKS0tTbGxsa5Ma2urmpqanMzMmTMVDoe1b98+J7N3716Fw2FXpqmpSa2trU6moqJClmUpLS3Nyezevdt1S31FRYUCgYAmTJjwSU8bAACMAIMqQt/85jf1q1/9SkePHlVjY6Oefvpp/c///I8WLVqkqKgo5eXlqbCwUGVlZWpqatKSJUs0evRo5eTkSJJs29ajjz6qgoIC7dq1SwcOHNDixYs1depUzZ07V5I0efJkzZ8/X7m5uaqtrVVtba1yc3OVnZ2tSZMmSZIyMzM1ZcoUBYNBHThwQLt27dKqVauUm5vrzODk5OTIsiwtWbJETU1NKisrU2FhofLz8z/2ozoAAOANMYMJnzp1SsFgUK2trbJtW3fccYfKy8uVkZEhSXryySd1/vx5LV26VKFQSNOnT1dFRYUSEhKcx3j++ecVExOjBx54QOfPn9d9992nl156SaNGjXIyr7zyilauXOncXbZw4UKVlJQ4+0eNGqUdO3Zo6dKlmj17tnw+n3JycrRx40YnY9u2KisrtWzZMk2bNk2JiYnKz89Xfn7+lT1TAABgxIkyhq9aHkgkEpFt2wqHw1fleqEJq3e41o+uzxryYwAA4DWX+/7Nb40BAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPoggBAADPGlQRKioq0uc//3klJCQoOTlZX/rSl/S73/3OlTHGaO3atQoEAvL5fJozZ44OHjzoynR1dWnFihVKSkpSfHy8Fi5cqBMnTrgyoVBIwWBQtm3Ltm0Fg0F1dHS4Ms3NzVqwYIHi4+OVlJSklStXqru725VpbGxUenq6fD6fxo0bp3Xr1skYM5jTBgAAI9SgilBVVZWWLVum2tpaVVZW6oMPPlBmZqbOnTvnZDZs2KDi4mKVlJSorq5Ofr9fGRkZOnPmjJPJy8tTWVmZSktLVV1drbNnzyo7O1u9vb1OJicnRw0NDSovL1d5ebkaGhoUDAad/b29vcrKytK5c+dUXV2t0tJSbd++XQUFBU4mEokoIyNDgUBAdXV12rRpkzZu3Kji4uIrerIAAMAIYz6B9vZ2I8lUVVUZY4zp6+szfr/frF+/3sl0dnYa27bNli1bjDHGdHR0mNjYWFNaWupkWlpaTHR0tCkvLzfGGHPo0CEjydTW1jqZmpoaI8kcPnzYGGPMzp07TXR0tGlpaXEy27ZtM5ZlmXA4bIwxZvPmzca2bdPZ2elkioqKTCAQMH19fZd1juFw2EhyHnOo3fzUz1wLAAD45C73/fsTXSMUDoclSWPHjpUkHTlyRG1tbcrMzHQylmUpPT1de/bskSTV19erp6fHlQkEAkpNTXUyNTU1sm1b06dPdzIzZsyQbduuTGpqqgKBgJOZN2+eurq6VF9f72TS09NlWZYrc/LkSR09evSS59TV1aVIJOJaAADAyHTFRcgYo/z8fN19991KTU2VJLW1tUmSUlJSXNmUlBRnX1tbm+Li4pSYmDhgJjk5ud8xk5OTXZmLj5OYmKi4uLgBMxfWL2QuVlRU5FyXZNu2xo8f/zHPBAAAuFZdcRFavny53nnnHW3btq3fvqioKNe6MabftotdnLlUfigy5s8XSn/UeNasWaNwOOwsx48fH3DcAADg2nVFRWjFihV688039fbbb+vGG290tvv9fkn9Z1va29udmRi/36/u7m6FQqEBM6dOnep33NOnT7syFx8nFAqpp6dnwEx7e7uk/rNWF1iWpTFjxrgWAAAwMg2qCBljtHz5cr3++uv65S9/qYkTJ7r2T5w4UX6/X5WVlc627u5uVVVVadasWZKktLQ0xcbGujKtra1qampyMjNnzlQ4HNa+ffuczN69exUOh12ZpqYmtba2OpmKigpZlqW0tDQns3v3btct9RUVFQoEApowYcJgTh0AAIxAgypCy5Yt08svv6xXX31VCQkJamtrU1tbm86fPy/pw4+b8vLyVFhYqLKyMjU1NWnJkiUaPXq0cnJyJEm2bevRRx9VQUGBdu3apQMHDmjx4sWaOnWq5s6dK0maPHmy5s+fr9zcXNXW1qq2tla5ubnKzs7WpEmTJEmZmZmaMmWKgsGgDhw4oF27dmnVqlXKzc11ZnFycnJkWZaWLFmipqYmlZWVqbCwUPn5+R/7UR0AAPCAwdyKJumSy4svvuhk+vr6zDPPPGP8fr+xLMvce++9prGx0fU458+fN8uXLzdjx441Pp/PZGdnm+bmZlfm/fffN4sWLTIJCQkmISHBLFq0yIRCIVfm2LFjJisry/h8PjN27FizfPly163yxhjzzjvvmHvuucdYlmX8fr9Zu3btZd86bwy3zwMAcC263PfvKGP4muWBRCIR2batcDh8Va4XmrB6h2v96PqsIT8GAABec7nv3/zWGAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8CyKEAAA8KxBF6Hdu3drwYIFCgQCioqK0htvvOHab4zR2rVrFQgE5PP5NGfOHB08eNCV6erq0ooVK5SUlKT4+HgtXLhQJ06ccGVCoZCCwaBs25Zt2woGg+ro6HBlmpubtWDBAsXHxyspKUkrV65Ud3e3K9PY2Kj09HT5fD6NGzdO69atkzFmsKcNAABGoEEXoXPnzunOO+9USUnJJfdv2LBBxcXFKikpUV1dnfx+vzIyMnTmzBknk5eXp7KyMpWWlqq6ulpnz55Vdna2ent7nUxOTo4aGhpUXl6u8vJyNTQ0KBgMOvt7e3uVlZWlc+fOqbq6WqWlpdq+fbsKCgqcTCQSUUZGhgKBgOrq6rRp0yZt3LhRxcXFgz1tAAAwEplPQJIpKytz1vv6+ozf7zfr1693tnV2dhrbts2WLVuMMcZ0dHSY2NhYU1pa6mRaWlpMdHS0KS8vN8YYc+jQISPJ1NbWOpmamhojyRw+fNgYY8zOnTtNdHS0aWlpcTLbtm0zlmWZcDhsjDFm8+bNxrZt09nZ6WSKiopMIBAwfX19l3WO4XDYSHIec6jd/NTPXAsAAPjkLvf9e0ivETpy5Ija2tqUmZnpbLMsS+np6dqzZ48kqb6+Xj09Pa5MIBBQamqqk6mpqZFt25o+fbqTmTFjhmzbdmVSU1MVCASczLx589TV1aX6+nonk56eLsuyXJmTJ0/q6NGjlzyHrq4uRSIR1wIAAEamIS1CbW1tkqSUlBTX9pSUFGdfW1ub4uLilJiYOGAmOTm53+MnJye7MhcfJzExUXFxcQNmLqxfyFysqKjIuS7Jtm2NHz/+408cAABck67KXWNRUVGudWNMv20XuzhzqfxQZMyfL5T+qPGsWbNG4XDYWY4fPz7guAEAwLVrSIuQ3++X1H+2pb293ZmJ8fv96u7uVigUGjBz6tSpfo9/+vRpV+bi44RCIfX09AyYaW9vl9R/1uoCy7I0ZswY1wIAAEamIS1CEydOlN/vV2VlpbOtu7tbVVVVmjVrliQpLS1NsbGxrkxra6uampqczMyZMxUOh7Vv3z4ns3fvXoXDYVemqalJra2tTqaiokKWZSktLc3J7N6923VLfUVFhQKBgCZMmDCUpw4AAK5Bgy5CZ8+eVUNDgxoaGiR9eIF0Q0ODmpubFRUVpby8PBUWFqqsrExNTU1asmSJRo8erZycHEmSbdt69NFHVVBQoF27dunAgQNavHixpk6dqrlz50qSJk+erPnz5ys3N1e1tbWqra1Vbm6usrOzNWnSJElSZmampkyZomAwqAMHDmjXrl1atWqVcnNznVmcnJwcWZalJUuWqKmpSWVlZSosLFR+fv7HflQHAAA8YLC3o7399ttGUr/l4YcfNsZ8eAv9M888Y/x+v7Esy9x7772msbHR9Rjnz583y5cvN2PHjjU+n89kZ2eb5uZmV+b99983ixYtMgkJCSYhIcEsWrTIhEIhV+bYsWMmKyvL+Hw+M3bsWLN8+XLXrfLGGPPOO++Ye+65x1iWZfx+v1m7du1l3zpvDLfPAwBwLbrc9+8oY/ia5YFEIhHZtq1wOHxVrheasHqHa/3o+qwhPwYAAF5zue/f/NYYAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwLIoQAADwrJjhHgDcLv41eolfpAcA4GphRggAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgWRQgAAHgW3yN0Dbj4u4X4XiEAAIYGM0IAAMCzmBG6BvHt0wAADA1mhAAAgGdRhAAAgGfx0ZiHcNE1AABuFKER4lLXDQEAgIHx0RgAAPAsZoQ8jLvPAABex4wQAADwLE/MCG3evFnPPfecWltbdfvtt+t73/ue7rnnnuEe1l+ky7nW6EpmjZh9AgD8JRrxRei1115TXl6eNm/erNmzZ+uHP/yh7r//fh06dEg33XTTcA/vmsSF2QCAkSLKGGOGexBX0/Tp0/W5z31OL7zwgrNt8uTJ+tKXvqSioqKP/ftIJCLbthUOhzVmzJghHx+lYnhczdkovqYAAIbf5b5/j+gZoe7ubtXX12v16tWu7ZmZmdqzZ88l/6arq0tdXV3OejgclvThE3o19HX96ao8LgZ20zf+34g81qU0fXveVXnc1Gd+8akdCwAG68L79sfN94zoIvSHP/xBvb29SklJcW1PSUlRW1vbJf+mqKhI3/72t/ttHz9+/FUZI3C12d8bmccCgMtx5swZ2bb9kftHdBG6ICoqyrVujOm37YI1a9YoPz/fWe/r69Mf//hHXX/99R/5N1cqEolo/PjxOn78+FX52O0viZfOVeJ8RzrOd+Ty0rlKI/t8jTE6c+aMAoHAgLkRXYSSkpI0atSofrM/7e3t/WaJLrAsS5ZlubZ95jOfuVpDlCSNGTNmxP0P8KN46Vwlznek43xHLi+dqzRyz3egmaALRvT3CMXFxSktLU2VlZWu7ZWVlZo1a9YwjQoAAPylGNEzQpKUn5+vYDCoadOmaebMmdq6dauam5v12GOPDffQAADAMBvxReif/umf9P7772vdunVqbW1Vamqqdu7cqZtvvnm4hybLsvTMM8/0+yhuJPLSuUqc70jH+Y5cXjpXyXvneykj/nuEAAAAPsqIvkYIAABgIBQhAADgWRQhAADgWRQhAADgWRShYbJ582ZNnDhR1113ndLS0vSrX/1quId0VRQVFenzn/+8EhISlJycrC996Uv63e9+N9zD+lQUFRUpKipKeXl5wz2Uq6qlpUWLFy/W9ddfr9GjR+uzn/2s6uvrh3tYQ+6DDz7Qt771LU2cOFE+n0+33HKL1q1bp76+vuEe2pDYvXu3FixYoEAgoKioKL3xxhuu/cYYrV27VoFAQD6fT3PmzNHBgweHZ7BDYKDz7enp0VNPPaWpU6cqPj5egUBAX/va13Ty5MnhG/An9HH/vv/X17/+dUVFRel73/vepza+4UQRGgavvfaa8vLy9PTTT+vAgQO65557dP/996u5uXm4hzbkqqqqtGzZMtXW1qqyslIffPCBMjMzde7cueEe2lVVV1enrVu36o477hjuoVxVoVBIs2fPVmxsrH7+85/r0KFD+u53v3vVv419OHznO9/Rli1bVFJSot/+9rfasGGDnnvuOW3atGm4hzYkzp07pzvvvFMlJSWX3L9hwwYVFxerpKREdXV18vv9ysjI0JkzZz7lkQ6Ngc73T3/6k/bv369/+7d/0/79+/X666/r3Xff1cKFC4dhpEPj4/59L3jjjTe0d+/ej/1ZihHF4FP3d3/3d+axxx5zbbvtttvM6tWrh2lEn5729nYjyVRVVQ33UK6aM2fOmFtvvdVUVlaa9PR08/jjjw/3kK6ap556ytx9993DPYxPRVZWlnnkkUdc27785S+bxYsXD9OIrh5JpqyszFnv6+szfr/frF+/3tnW2dlpbNs2W7ZsGYYRDq2Lz/dS9u3bZySZY8eOfTqDuoo+6nxPnDhhxo0bZ5qamszNN99snn/++U99bMOBGaFPWXd3t+rr65WZmenanpmZqT179gzTqD494XBYkjR27NhhHsnVs2zZMmVlZWnu3LnDPZSr7s0339S0adP01a9+VcnJybrrrrv0ox/9aLiHdVXcfffd2rVrl959911J0m9+8xtVV1fri1/84jCP7Oo7cuSI2traXK9blmUpPT3dE69b0oevXVFRUSNytlP68AfGg8GgnnjiCd1+++3DPZxP1Yj/Zum/NH/4wx/U29vb70dfU1JS+v047EhjjFF+fr7uvvtupaamDvdwrorS0lLt379fdXV1wz2UT8Xvf/97vfDCC8rPz9c3v/lN7du3TytXrpRlWfra17423MMbUk899ZTC4bBuu+02jRo1Sr29vXr22Wf10EMPDffQrroLr02Xet06duzYcAzpU9XZ2anVq1crJydnRP4wqfThR78xMTFauXLlcA/lU0cRGiZRUVGudWNMv20jzfLly/XOO++ourp6uIdyVRw/flyPP/64KioqdN111w33cD4VfX19mjZtmgoLCyVJd911lw4ePKgXXnhhxBWh1157TS+//LJeffVV3X777WpoaFBeXp4CgYAefvjh4R7ep8KLr1s9PT168MEH1dfXp82bNw/3cK6K+vp6ff/739f+/ftH/L/npfDR2KcsKSlJo0aN6jf7097e3u+/tkaSFStW6M0339Tbb7+tG2+8cbiHc1XU19ervb1daWlpiomJUUxMjKqqqvSDH/xAMTEx6u3tHe4hDrkbbrhBU6ZMcW2bPHnyiLzw/4knntDq1av14IMPaurUqQoGg/rGN76hoqKi4R7aVef3+yXJc69bPT09euCBB3TkyBFVVlaO2NmgX/3qV2pvb9dNN93kvHYdO3ZMBQUFmjBhwnAP76qjCH3K4uLilJaWpsrKStf2yspKzZo1a5hGdfUYY7R8+XK9/vrr+uUvf6mJEycO95Cumvvuu0+NjY1qaGhwlmnTpmnRokVqaGjQqFGjhnuIQ2727Nn9vg7h3Xff/Yv4UeOh9qc//UnR0e6XzFGjRo2Y2+cHMnHiRPn9ftfrVnd3t6qqqkbk65b0/5eg9957T2+99Zauv/764R7SVRMMBvXOO++4XrsCgYCeeOIJ/eIXvxju4V11fDQ2DPLz8xUMBjVt2jTNnDlTW7duVXNzsx577LHhHtqQW7ZsmV599VX993//txISEpz/orRtWz6fb5hHN7QSEhL6XfsUHx+v66+/fsReE/WNb3xDs2bNUmFhoR544AHt27dPW7du1datW4d7aENuwYIFevbZZ3XTTTfp9ttv14EDB1RcXKxHHnlkuIc2JM6ePav//d//ddaPHDmihoYGjR07VjfddJPy8vJUWFioW2+9VbfeeqsKCws1evRo5eTkDOOor9xA5xsIBPSVr3xF+/fv189+9jP19vY6r11jx45VXFzccA37in3cv+/FRS82NlZ+v1+TJk36tIf66Rvem9a86z/+4z/MzTffbOLi4sznPve5EXs7uaRLLi+++OJwD+1TMdJvnzfGmJ/+9KcmNTXVWJZlbrvtNrN169bhHtJVEYlEzOOPP25uuukmc91115lbbrnFPP3006arq2u4hzYk3n777Uv+f/Xhhx82xnx4C/0zzzxj/H6/sSzL3HvvvaaxsXF4B/0JDHS+R44c+cjXrrfffnu4h35FPu7f92Jeun0+yhhjPqXOBQAA8BeFa4QAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBnUYQAAIBn/X+BBAF0l5654wAAAABJRU5ErkJggg==","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#plot histogram of median\n","plt.hist(grouped_out_tx_df['median'], bins=100)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","time_delta = np.linspace(0, 31, 100)\n","gammas = [0.1, 0.3, 0.5, 0.7, 0.9]  # different gamma values\n","\n","# Create a new figure with a specified size\n","plt.figure(figsize=(10, 6))  # You can adjust the size as needed\n","\n","# Plot the exponential decay for each gamma\n","for gamma in gammas:\n","    decay = np.exp(-gamma * time_delta)\n","    plt.plot(time_delta, decay, label=f'gamma={gamma}')\n","\n","plt.title('Exponential Decay for Different Gamma Values')\n","plt.xlabel('Time Delta (days)')\n","plt.ylabel('Exponential Decay')\n","\n","# Set x and y ticks\n","plt.xticks(np.arange(0, max(time_delta)+1, 1))\n","plt.yticks(np.arange(0, 1.1, 0.1))  # assuming the max decay value to be 1\n","\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["recency_avg.write.mode('overwrite').parquet(\"data/parquet_files/recency_avg.parquet\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["7224385\n"]}],"source":["recency_test = pd.read_parquet(\"data/parquet_files/recency_avg.parquet\")\n","print(len(recency_test))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Anomolous ETH transactions"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["median_k = 1.4826\n","# Compute the median of the incoming Ethereum transactions\n","incoming_median = transactions_df.filter(col(\"asset\") == \"ETH\") \\\n","    .filter(col(\"to_id\").isNotNull()) \\\n","    .fillna({\"asset_value\": 0}) \\\n","    .groupBy(\"to_id\") \\\n","    .agg(F.median('asset_value').alias(\"median_eth_in\"))\n","\n","outgoing_median = transactions_df.filter(col(\"asset\") == \"ETH\") \\\n","    .fillna({\"asset_value\": 0}) \\\n","    .groupBy(\"from_id\") \\\n","    .agg(F.median('asset_value').alias(\"median_eth_out\"))\n","\n","# Alias the original DataFrame\n","transactions_df_alias = transactions_df.alias(\"transactions_df\")\n","\n","# Join the original DataFrame with the one containing the medians\n","incoming_joined = transactions_df_alias.filter(col(\"asset\") == \"ETH\") \\\n","    .filter(col(\"to_id\").isNotNull()) \\\n","    .fillna({\"asset_value\": 0}) \\\n","    .join(incoming_median, transactions_df_alias.to_id == incoming_median.to_id, 'inner')\n","\n","# Compute the absolute deviations from the median\n","incoming_devs = incoming_joined.withColumn(\"abs_dev\", median_k*F.abs(incoming_joined.asset_value - incoming_joined.median_eth_in))\n","\n","# Compute the median of these absolute deviations\n","incoming_mad = incoming_devs.groupBy(\"transactions_df.to_id\") \\\n","    .agg(F.median('abs_dev').alias(\"mad_eth_in\"))\n","\n","# Follow similar process for outgoing transactions\n","outgoing_joined = transactions_df_alias.filter(col(\"asset\") == \"ETH\") \\\n","    .fillna({\"asset_value\": 0}) \\\n","    .join(outgoing_median, transactions_df_alias.from_id == outgoing_median.from_id, 'inner')\n","\n","outgoing_devs = outgoing_joined.withColumn(\"abs_dev\", median_k*F.abs(outgoing_joined.asset_value - outgoing_joined.median_eth_out))\n","\n","outgoing_mad = outgoing_devs.groupBy(\"transactions_df.from_id\") \\\n","    .agg(F.median('abs_dev').alias(\"mad_eth_out\"))\n","\n","# Join the two DataFrames and join with median DataFrame\n","outgoing_median_mad = outgoing_median.join(outgoing_mad, \"from_id\")\n","outgoing_median_mad = outgoing_median_mad.withColumnRenamed(\"from_id\", \"address_id\")\n","outgoing_median_mad = outgoing_median_mad.alias(\"outgoing_median_mad\")\n","\n","incoming_median_mad = incoming_median.join(incoming_mad, \"to_id\")\n","incoming_median_mad = incoming_median_mad.withColumnRenamed(\"to_id\", \"address_id\")\n","incoming_median_mad = incoming_median_mad.alias(\"incoming_median_mad\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def compute_zscore(value, median, mad):\n","    return F.when(mad != 0, (value - median) / mad).otherwise(0)\n","\n","transfer_df_expanded = transactions_df.filter(col(\"asset\") == \"ETH\")\\\n","                        .join(outgoing_median_mad, transactions_df.from_id == outgoing_median_mad.address_id, \"left\")\n","transfer_df_expanded = transfer_df_expanded.join(incoming_median_mad, transfer_df_expanded.to_id == incoming_median_mad.address_id, \"left\")\\\n","                        .fillna({\"median_eth_out\": 0, \"mad_eth_out\": 0, \"median_eth_in\": 0, \"mad_eth_in\": 0})\n","# Define a function to calculate the z-score\n","\n","# Apply the function to the \"asset_value_in\" and \"asset_value_out\" columns\n","transfer_df_expanded = transfer_df_expanded.withColumn(\"zscore_eth_in\", \n","                                   compute_zscore(F.col(\"asset_value\"), \n","                                                  F.col(\"median_eth_in\"), \n","                                                  F.col(\"mad_eth_in\")))\n","\n","transfer_df_expanded = transfer_df_expanded.withColumn(\"zscore_eth_out\", \n","                                   compute_zscore(F.col(\"asset_value\"), \n","                                                  F.col(\"median_eth_out\"), \n","                                                  F.col(\"mad_eth_out\")))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["outgoing_outliers = transfer_df_expanded.groupBy(\"from_id\")\\\n","    .agg(F.sum(F.when((F.col(\"zscore_eth_out\") > 3.5) | (F.col(\"zscore_eth_out\") < -3.5), 1).otherwise(0))\\\n","    .alias(\"num_outliers_eth_out\"))\n","outgoing_outliers = outgoing_outliers.withColumnRenamed(\"from_id\", \"address_id\")\n","\n","incoming_outliers = transfer_df_expanded.groupBy(\"to_id\")\\\n","    .agg(F.sum(F.when((F.col(\"zscore_eth_in\") > 3.5) | (F.col(\"zscore_eth_in\") < -3.5), 1).otherwise(0))\\\n","    .alias(\"num_outliers_eth_in\"))\n","incoming_outliers = incoming_outliers.withColumnRenamed(\"to_id\", \"address_id\")"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["merged_outliers = outgoing_outliers.join(incoming_outliers, \"address_id\", \"outer\").fillna(0)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["merged_outliers.write.mode('overwrite').parquet(\"data/parquet_files/outliers.parquet\")\n","# transfer_df_expanded.select(\"tx_id\", \"from_id\", \"to_id\", \"timestamp\", \"asset_value\", \"zscore_eth_in\", \"zscore_eth_out\").write.mode('overwrite').parquet(\"data/parquet_files/transfer_df.parquet\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["zscores_df = spark.read.parquet(\"data/parquet_files/transfer_df_train.parquet\")\n","zscores_df = zscores_df.fillna({\"zscore_eth_in\": 0, \"zscore_eth_out\": 0})\n","# Convert the DataFrame columns to lists\n","zscore_eth_in_list = zscores_df.select(\"zscore_eth_in\").rdd.flatMap(lambda x: x).collect()\n","zscore_eth_out_list = zscores_df.select(\"zscore_eth_out\").rdd.flatMap(lambda x: x).collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1600x600 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Create a figure with 2 subplots side by side\n","fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n","\n","# Plot the histogram for zscore_eth_in in the first subplot\n","axs[0].hist(zscore_eth_in_list, bins=30, alpha=0.5, color='blue')\n","axs[0].set_xlabel('Z-Score')\n","axs[0].set_ylabel('Frequency')\n","axs[0].set_title('Frequency Distribution of Z-Scores for eth_in')\n","axs[0].set_ylim([0, 100]) \n","\n","# Plot the histogram for zscore_eth_out in the second subplot\n","axs[1].hist(zscore_eth_out_list, bins=30, alpha=0.5, color='orange')\n","axs[1].set_xlabel('Z-Score')\n","axs[1].set_ylabel('Frequency')\n","axs[1].set_title('Frequency Distribution of Z-Scores for eth_out')\n","axs[1].set_ylim([0, 100])\n","\n","# Display the plots\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#count number of transactions with zscore above 3.5 or below -3.5\n","outliers_out = [zscore for zscore in zscore_eth_out_list if zscore > 3.5 or zscore < -3.5]\n","outliers_in = [zscore for zscore in zscore_eth_in_list if zscore > 3.5 or zscore < -3.5]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Total number of transactions:  31080408\n","Number of outliers for eth_out:  2819213\n","Number of outliers for eth_in:  2747765\n"]}],"source":["print(\"Total number of transactions: \", len(zscore_eth_out_list))\n","print(\"Number of outliers for eth_out: \", len(outliers_out))\n","print(\"Number of outliers for eth_in: \", len(outliers_in))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Merge DFs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfs_1 = [transactions_count, transactions_timestamps, contracts_created, avg_tx, unique_received_transactions, unique_sent_transactions, \n","         incoming_eth, outgoing_eth, total_erc_20_tnx, erc20eth_out, erc20eth_in, min_erc20token_in, min_erc20token_out]\n","account_data_1 = reduce(lambda a, b: a.join(b, \"address_id\", \"outer\"), dfs_1)\n","account_data_1 = account_data_1.repartition(100)\n","account_data_1.write.mode('overwrite').parquet(\"data/parquet_files/account_data_1_train.parquet\")\n","account_data_1 = None"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["dfs_2 = [max_erc20token_in, max_erc20token_out, num_unique_erc20tokens_out, num_unique_erc20tokens_in, \n","         total_erc_1155_tnx, total_erc_721_tnx, num_unique_erc721asset_out, num_unique_erc721asset_in]\n","account_data_2 = reduce(lambda a, b: a.join(b, \"address_id\", \"outer\"), dfs_2)\n","account_data_2.write.mode('overwrite').parquet(\"data/parquet_files/account_data_2_train.parquet\")\n","account_data_2 = None"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["fillna_values = {\n","    \"outgoing_tx_count\": 0, \"incoming_tx_count\": 0, \"time_difference_in_minutes\": 0, \"contracts_created\": 0,\n","    \"avg_time_diff_out_minutes\": 0, \"avg_time_diff_in_minutes\": 0, \"total_avg_time_diff_minutes\": 0,\n","    \"unique_received_transactions\": 0, \"unique_sent_transactions\": 0, \"total_incoming_eth\": 0,\n","    \"total_outgoing_eth\": 0, \"outgoing_erc_20_tnx\": 0, \"incoming_erc_20_tnx\": 0, \"total_erc_20_tnx\": 0,\n","    \"total_outgoing_erc20eth\": 0, \"total_incoming_erc20eth\": 0, \"min_erc20token_in\": 0,\n","    \"min_erc20token_out\": 0, \"max_erc20token_in\": 0, \"max_erc20token_out\": 0,\n","    \"num_unique_erc20tokens_out\": 0, \"num_unique_erc20tokens_in\": 0, \"outgoing_erc_1155_tnx\": 0,\n","    \"incoming_erc_1155_tnx\": 0, \"total_erc_1155_tnx\": 0, \"outgoing_erc_721_tnx\": 0,\n","    \"incoming_erc_721_tnx\": 0, \"total_erc_721_tnx\": 0, \"num_unique_erc721asset_out\": 0,\n","    \"num_unique_erc721asset_in\": 0\n","}\n","\n","account_data_1 = spark.read.parquet(\"data/parquet_files/account_data_1.parquet\")\n","account_data_2 = spark.read.parquet(\"data/parquet_files/account_data_2.parquet\")\n","daily_gini_index = spark.read.parquet(\"data/parquet_files/daily_gini_idx.parquet\")\n","weekly_gini_index = spark.read.parquet(\"data/parquet_files/weekly_gini_idx.parquet\")\n","total_gini_index = spark.read.parquet(\"data/parquet_files/total_gini_idx.parquet\")\n","recency_avg = spark.read.parquet(\"data/parquet_files/recency_avg.parquet\")\n","outliers = spark.read.parquet(\"data/parquet_files/outliers.parquet\")\n","merge_saved_df = [account_data_1, account_data_2, daily_gini_index, weekly_gini_index, total_gini_index, recency_avg, outliers]\n","account_df = reduce(lambda a, b: a.join(b, \"address_id\", \"outer\"), merge_saved_df)\n","account_df = account_df.fillna(fillna_values)\n","\n","account_df = account_df.withColumn(\"total_tx_with_contracts\", \n","                                   F.col(\"outgoing_tx_count\") + F.col(\"incoming_tx_count\") + F.col(\"contracts_created\"))\n","\n","account_df = account_df.select([\n","    \"address_id\", \"outgoing_tx_count\", \"incoming_tx_count\", \"unique_received_transactions\", \"unique_sent_transactions\",\n","    \"contracts_created\", \"total_tx_with_contracts\", \"total_incoming_eth\", \"total_outgoing_eth\", \"time_difference_in_minutes\",\n","    \"avg_time_diff_out_minutes\", \"avg_time_diff_in_minutes\", \"total_avg_time_diff_minutes\", \"outgoing_erc_20_tnx\",\n","    \"incoming_erc_20_tnx\", \"total_erc_20_tnx\", \"total_outgoing_erc20eth\", \"total_incoming_erc20eth\", \"min_erc20token_in\",\n","    \"min_erc20token_out\", \"max_erc20token_in\", \"max_erc20token_out\", \"num_unique_erc20tokens_out\",\n","    \"num_unique_erc20tokens_in\", \"outgoing_erc_1155_tnx\", \"incoming_erc_1155_tnx\", \"total_erc_1155_tnx\",\n","    \"outgoing_erc_721_tnx\", \"incoming_erc_721_tnx\", \"total_erc_721_tnx\", \"num_unique_erc721asset_out\",\n","    \"num_unique_erc721asset_in\", \"daily_from_gini_index\", \"daily_to_gini_index\", \"weekly_from_gini_index\",\n","    \"weekly_to_gini_index\", \"daily_total_gini_index\", \"weekly_total_gini_index\", \"median_recency_out\", \"median_recency_in\",\n","    \"num_outliers_eth_out\", \"num_outliers_eth_in\"\n","])\n","\n","account_df = account_df.filter(col(\"daily_total_gini_index\").isNotNull())"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+----------+-----------------+-----------------+----------------------------+------------------------+-----------------+-----------------------+------------------+------------------+--------------------------+-------------------------+------------------------+---------------------------+-------------------+-------------------+----------------+-----------------------+-----------------------+-----------------+------------------+-----------------+------------------+--------------------------+-------------------------+---------------------+---------------------+------------------+--------------------+--------------------+-----------------+--------------------------+-------------------------+---------------------+-------------------+----------------------+--------------------+----------------------+-----------------------+------------------+-----------------+--------------------+-------------------+\n","|address_id|outgoing_tx_count|incoming_tx_count|unique_received_transactions|unique_sent_transactions|contracts_created|total_tx_with_contracts|total_incoming_eth|total_outgoing_eth|time_difference_in_minutes|avg_time_diff_out_minutes|avg_time_diff_in_minutes|total_avg_time_diff_minutes|outgoing_erc_20_tnx|incoming_erc_20_tnx|total_erc_20_tnx|total_outgoing_erc20eth|total_incoming_erc20eth|min_erc20token_in|min_erc20token_out|max_erc20token_in|max_erc20token_out|num_unique_erc20tokens_out|num_unique_erc20tokens_in|outgoing_erc_1155_tnx|incoming_erc_1155_tnx|total_erc_1155_tnx|outgoing_erc_721_tnx|incoming_erc_721_tnx|total_erc_721_tnx|num_unique_erc721asset_out|num_unique_erc721asset_in|daily_from_gini_index|daily_to_gini_index|weekly_from_gini_index|weekly_to_gini_index|daily_total_gini_index|weekly_total_gini_index|median_recency_out|median_recency_in|num_outliers_eth_out|num_outliers_eth_in|\n","+----------+-----------------+-----------------+----------------------------+------------------------+-----------------+-----------------------+------------------+------------------+--------------------------+-------------------------+------------------------+---------------------------+-------------------+-------------------+----------------+-----------------------+-----------------------+-----------------+------------------+-----------------+------------------+--------------------------+-------------------------+---------------------+---------------------+------------------+--------------------+--------------------+-----------------+--------------------------+-------------------------+---------------------+-------------------+----------------------+--------------------+----------------------+-----------------------+------------------+-----------------+--------------------+-------------------+\n","|         0|                0|                0|                           0|                       0|                0|                      0|                 0|                 0|                         0|                        0|                       0|                          0|                  0|                  0|               0|                      0|                      0|                0|                 0|                0|                 0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|              1880507|            1634953|               1880507|             1634953|                     0|                      0|                 0|                0|              937277|             937277|\n","+----------+-----------------+-----------------+----------------------------+------------------------+-----------------+-----------------------+------------------+------------------+--------------------------+-------------------------+------------------------+---------------------------+-------------------+-------------------+----------------+-----------------------+-----------------------+-----------------+------------------+-----------------+------------------+--------------------------+-------------------------+---------------------+---------------------+------------------+--------------------+--------------------+-----------------+--------------------------+-------------------------+---------------------+-------------------+----------------------+--------------------+----------------------+-----------------------+------------------+-----------------+--------------------+-------------------+\n","\n"]}],"source":["#count null values in each column\n","account_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in account_df.columns]).show()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/07/02 19:45:53 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","                                                                                \r"]}],"source":["account_df.write.mode('overwrite').parquet(\"data/parquet_files/account_df.parquet\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 154:==============================>                         (6 + 5) / 11]\r"]},{"name":"stdout","output_type":"stream","text":["+----------+-----------------+-----------------+----------------------------+------------------------+-----------------+-----------------------+--------------------+-------------------+--------------------------+-------------------------+------------------------+---------------------------+-------------------+-------------------+----------------+-----------------------+-----------------------+-----------------+------------------+-----------------+------------------+--------------------------+-------------------------+---------------------+---------------------+------------------+--------------------+--------------------+-----------------+--------------------------+-------------------------+---------------------+-------------------+----------------------+--------------------+----------------------+-----------------------+--------------------+--------------------+--------------------+-------------------+\n","|address_id|outgoing_tx_count|incoming_tx_count|unique_received_transactions|unique_sent_transactions|contracts_created|total_tx_with_contracts|  total_incoming_eth| total_outgoing_eth|time_difference_in_minutes|avg_time_diff_out_minutes|avg_time_diff_in_minutes|total_avg_time_diff_minutes|outgoing_erc_20_tnx|incoming_erc_20_tnx|total_erc_20_tnx|total_outgoing_erc20eth|total_incoming_erc20eth|min_erc20token_in|min_erc20token_out|max_erc20token_in|max_erc20token_out|num_unique_erc20tokens_out|num_unique_erc20tokens_in|outgoing_erc_1155_tnx|incoming_erc_1155_tnx|total_erc_1155_tnx|outgoing_erc_721_tnx|incoming_erc_721_tnx|total_erc_721_tnx|num_unique_erc721asset_out|num_unique_erc721asset_in|daily_from_gini_index|daily_to_gini_index|weekly_from_gini_index|weekly_to_gini_index|daily_total_gini_index|weekly_total_gini_index|  median_recency_out|   median_recency_in|num_outliers_eth_out|num_outliers_eth_in|\n","+----------+-----------------+-----------------+----------------------------+------------------------+-----------------+-----------------------+--------------------+-------------------+--------------------------+-------------------------+------------------------+---------------------------+-------------------+-------------------+----------------+-----------------------+-----------------------+-----------------+------------------+-----------------+------------------+--------------------------+-------------------------+---------------------+---------------------+------------------+--------------------+--------------------+-----------------+--------------------------+-------------------------+---------------------+-------------------+----------------------+--------------------+----------------------+-----------------------+--------------------+--------------------+--------------------+-------------------+\n","|    256593|                1|                3|                           1|                       1|                0|                      4| 0.30722562223672867|0.10813048481941223|        31551.533333333333|                      0.0|      15775.766666666666|         10517.177777777777|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0|0.016375048086047173|                   0|                  1|\n","|    576472|                4|                4|                           1|                       3|                0|                      8|   1.023318812251091| 1.0210004299879074|        35550.333333333336|       11849.655555555557|                 11849.5|          5078.619047619048|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|          0.8666667|                   0.0|                 0.0|             0.8666667|                    0.0| 0.06780830025672913| 0.06780038960278034|                   0|                  0|\n","|    378340|                4|                0|                           0|                       4|                0|                      4|                 0.0| 2.9979999661445618|                   31521.8|       10507.266666666666|                     0.0|         10507.266666666666|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|               null|                   0.0|                null|             0.8666667|                    0.0| 0.09112530387938023|                 0.0|                   1|                  0|\n","|    976057|                1|                3|                           1|                       1|                0|                      4|  0.6858389675617218| 1.2678215503692627|        31659.333333333332|                      0.0|      15829.666666666666|         10553.111111111111|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0|0.008270625956356525|                   0|                  0|\n","|    282418|                8|                0|                           0|                       6|                0|                      8|                 0.0|                0.0|        34608.416666666664|        4944.059523809524|                     0.0|          4944.059523809524|                  4|                  0|               4|                    0.0|                    0.0|              0.0|          860.6069|              0.0|             999.0|                         2|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|               null|                   0.0|                null|             0.8666667|                    0.0|  0.6065356433391571|                 0.0|                   0|                  0|\n","|    603449|                4|                4|                           1|                       1|                0|                      8|                 0.0|                0.0|         38586.88333333333|       12860.483333333334|      12859.972222222223|          5512.411904761904|                  4|                  4|               8|                    0.0|                    0.0|           2000.0|            2000.0|           3000.0|            3000.0|                         1|                        1|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|          0.8666667|                   0.0|                 0.0|             0.8666667|                    0.0| 0.04997955076396465| 0.04998130165040493|                null|               null|\n","|    367985|                2|                8|                           1|                       1|                0|                     10|   4.016177743673325| 2.5094754695892334|                  39049.85|                 26840.15|       5573.578571428571|          4338.872222222222|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.93333334|         0.73333335|                   0.5|                0.15|             0.7733333|                    0.0|0.001864345744252205| 0.28861935436725616|                   0|                  0|\n","|    867002|                1|                3|                           1|                       1|                0|                      4| 0.29805275797843933|0.20064598321914673|         33863.26666666667|                      0.0|      16931.633333333335|         11287.755555555555|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0|0.010862061753869057|                   0|                  0|\n","|    203907|                1|                3|                           2|                       1|                0|                      4|  0.2726959362626076| 0.9297288060188293|        33100.433333333334|                      0.0|       9408.891666666666|         11033.477777777776|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0| 0.09200780093669891|                   0|                  1|\n","|    627354|                8|                0|                           0|                       5|                0|                      8|                 0.0|                0.0|                  30551.85|                  4364.55|                     0.0|                    4364.55|                  4|                  0|               4|                    0.0|                    0.0|              0.0|             340.0|              0.0|          1499.491|                         1|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|               null|                   0.0|                null|             0.8666667|                    0.0|  0.6093312650918961|                 0.0|                   0|                  0|\n","|    209676|                5|                5|                           1|                       1|                0|                     10|    2.49651500582695|  2.489599734544754|                  37556.65|        9325.304166666667|               9358.7375|          4172.961111111111|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8333333|          0.8333333|                   0.0|                 0.0|             0.8333333|                    0.0|  0.1260215789079666| 0.12288706004619598|                   0|                  2|\n","|    256342|                1|                3|                           1|                       1|                0|                      4|  0.2977859899401665| 0.6499999761581421|                  36319.15|                      0.0|      15372.716666666667|         12106.383333333333|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0|0.014070029370486736|                   0|                  0|\n","|    451232|                1|                3|                           1|                       1|                0|                      4|  0.5994786620140076|  1.289865255355835|        30281.633333333335|                      0.0|      15140.816666666668|         10093.877777777778|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0|0.034054432064294815|                   0|                  1|\n","|    627519|                1|                3|                           1|                       1|                0|                      4|  0.6498136520385742|  1.402063012123108|         35855.38333333333|                      0.0|      17927.691666666666|         11951.794444444444|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0|0.006266842596232891|                   0|                  0|\n","|    188995|                4|                4|                           1|                       1|                0|                      8| 0.11274344101548195|0.11274344101548195|        34471.083333333336|       11490.361111111111|      11490.361111111111|          4924.440476190476|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|          0.8666667|                   0.0|                 0.0|             0.8666667|                    0.0| 0.06100291293114424| 0.06100291293114424|                   0|                  0|\n","|    664209|                1|                3|                           1|                       1|                0|                      4|  0.2969662919640541|  1.089434027671814|                   37737.1|                      0.0|                18868.55|         12579.033333333333|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.96666664|                0.9|                  0.75|                0.25|             0.8666667|                    0.0|                 0.0| 0.01739698462188244|                   0|                  0|\n","|    205647|                8|                4|                           4|                       2|                0|                     12|                 0.0|                0.0|        30186.866666666665|        4312.409523809523|       9458.522222222224|          2744.260606060606|                  4|                  4|               8|                    0.0|                    0.0|           5200.0|            5200.0|           5390.0|           10720.0|                         1|                        1|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|          0.8666667|                   0.0|                 0.0|             0.8611111|                    0.0|  0.5830879583954811|  0.1318901851773262|                   0|                  0|\n","|    693103|                3|                1|                           1|                       1|                0|                      4|0.013782200403511524|0.00674595633699937|        24049.133333333335|                   7712.0|                     0.0|          8016.377777777778|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|                  0.9|         0.96666664|                  0.25|                0.75|             0.8666667|                    0.0| 0.14790670573711395|                 0.0|                   0|                  0|\n","|    210793|                4|                0|                           0|                       2|                0|                      4|                 0.0|  39.99855995178223|        29525.916666666668|        9841.972222222223|                     0.0|          9841.972222222223|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|            0.8666667|               null|                   0.0|                null|             0.8666667|                    0.0|  0.0819916408509016|                 0.0|                   1|                  0|\n","|    230761|                2|                2|                           2|                       2|                0|                      4|  0.3500000014901161|  0.919244110584259|                  39405.65|                 39405.65|                 8061.55|         13135.216666666667|                  0|                  0|               0|                    0.0|                    0.0|              0.0|               0.0|              0.0|               0.0|                         0|                        0|                    0|                    0|                 0|                   0|                   0|                0|                         0|                        0|           0.93333334|         0.93333334|                   0.5|                 0.5|             0.8666667|                    0.0|1.360269379802048...| 0.09323456138372421|                   0|                  0|\n","+----------+-----------------+-----------------+----------------------------+------------------------+-----------------+-----------------------+--------------------+-------------------+--------------------------+-------------------------+------------------------+---------------------------+-------------------+-------------------+----------------+-----------------------+-----------------------+-----------------+------------------+-----------------+------------------+--------------------------+-------------------------+---------------------+---------------------+------------------+--------------------+--------------------+-----------------+--------------------------+-------------------------+---------------------+-------------------+----------------------+--------------------+----------------------+-----------------------+--------------------+--------------------+--------------------+-------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stderr","output_type":"stream","text":["23/07/02 20:17:31 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 302158 ms exceeds timeout 120000 ms\n","23/07/02 20:17:31 WARN SparkContext: Killing executors is not supported by current scheduler.\n","23/07/02 20:17:37 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 20:17:37 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 20:17:46 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 20:17:46 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 20:17:56 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:17:56 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:18:06 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:18:06 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:14 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:14 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:24 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:24 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:34 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:34 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:44 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:44 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:54 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:23:54 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:04 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:04 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:14 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:14 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:24 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:24 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:34 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:34 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:44 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:24:44 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:29:53 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:29:53 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:30:03 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 20:30:03 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 20:30:13 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:30:13 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:30:23 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:30:23 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:30:33 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:30:33 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:31:57 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:31:57 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:48:46 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 20:48:46 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:04:07 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:04:07 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:37:47 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:37:47 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:51:24 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:51:24 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:51:34 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:51:34 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:51:44 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:51:44 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:51:54 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:51:54 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:52:04 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:52:04 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:52:14 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:52:14 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:52:24 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:52:24 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:58:10 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:58:10 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:58:20 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:58:20 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:58:30 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:58:30 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:58:40 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:58:40 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:58:50 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:58:50 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:00 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:59:00 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:59:10 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:10 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:20 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:20 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:30 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:30 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:40 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:59:40 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 21:59:50 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 21:59:50 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:00:00 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:00:00 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:00:10 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:00:10 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:00:20 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:00:20 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:00:30 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:00:30 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:00:40 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:00:40 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:00:50 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:00:50 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:01:00 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:01:00 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:01:10 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:01:10 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:01:20 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:01:20 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:01:30 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:01:30 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:01:40 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:01:40 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:01:50 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:01:50 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:00 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:00 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:10 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:10 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:20 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:20 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:30 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:30 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:40 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:40 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:50 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:02:50 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n","\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n","\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n","\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n","\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n","\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n","\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n","\tat scala.concurrent.Promise.complete(Promise.scala:53)\n","\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n","\tat scala.concurrent.Promise.success(Promise.scala:86)\n","\tat scala.concurrent.Promise.success$(Promise.scala:86)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n","\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n","\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n","\t... 8 more\n","23/07/02 22:03:00 ERROR Inbox: Ignoring error\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:03:00 WARN Executor: Issue communicating with driver in heartbeater\n","org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n","\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n","\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n","\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n","\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n","\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n","\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n","\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n","\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n","\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n","\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n","\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n","\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n","\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n","\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n","\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n","\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n","\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n","\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n","\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n","\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n","\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n","\t... 3 more\n","Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.222.103:62404\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n","\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n","\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n","\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n","\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n","\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n","\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n","\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n","\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n","\tat scala.concurrent.Future.flatMap(Future.scala:306)\n","\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n","\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n","\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n","\t... 17 more\n","23/07/02 22:03:00 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n","----------------------------------------\n","Exception happened during processing of request from ('127.0.0.1', 62431)\n","Traceback (most recent call last):\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n","    self.process_request(request, client_address)\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/socketserver.py\", line 347, in process_request\n","    self.finish_request(request, client_address)\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/socketserver.py\", line 360, in finish_request\n","    self.RequestHandlerClass(request, client_address, self)\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/socketserver.py\", line 747, in __init__\n","    self.handle()\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pyspark/accumulators.py\", line 281, in handle\n","    poll(accum_updates)\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pyspark/accumulators.py\", line 253, in poll\n","    if func():\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n","    num_updates = read_int(self.rfile)\n","  File \"/Users/nat_rng/opt/anaconda3/envs/py38/lib/python3.8/site-packages/pyspark/serializers.py\", line 596, in read_int\n","    raise EOFError\n","EOFError\n","----------------------------------------\n"]}],"source":["account_df = spark.read.parquet(\"data/parquet_files/account_df.parquet\")\n","account_df.orderBy(F.asc('weekly_total_gini_index')).show()"]}],"metadata":{"kernelspec":{"display_name":"py38","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
